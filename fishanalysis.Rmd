---
title: "Analysis"
author: "Jenny Rogers"
date: "5/6/2022"
output: html_document
---


load libraries

```{r}

library(tidyverse)
library(sf)
library(lwgeom)


```


load data:
flowline
huc12
huc10
huc8
all_fish_event



Chunk1: load dataframes
```{r}
flowline <- st_read("C:/Users/jrogers/Documents/necascFreshwaterBio/SpatialData/NHDplus/NHDflowline/NHDflowline_NE.shp")
huc8 <- st_read("C:/Users/jrogers/Documents/necascFreshwaterBio/SpatialData/NHDplus/WBDHU8/WBDHU8_NE.shp")
huc10 <- st_read("C:/Users/jrogers/Documents/necascFreshwaterBio/SpatialData/NHDplus/WBDHU10/WBDHU10_NE.shp")
huc12 <- st_read("C:/Users/jrogers/Documents/necascFreshwaterBio/SpatialData/NHDplus/WBDHU12/WBDHU12_NE.shp")

fish_event <- st_read("C:/Users/jrogers/Documents/necascFreshwaterBio/SpatialData/sppdata/all_fish_event.shp")

```


Chuck2:
Spatially join the huc and the flowline data to the all_fish_event. now every fish surveying event is aligned with hdyrologic data.
These two datasets have removed the lentic surveys.

```{r}

#prepare the huc files - select the attributes we want and remove the duplicated rows
#21 survey points are lost from falling outside the watershed boundaries that were clipped to the state outlines.

huc8 <- huc8 %>% 
  select(tnmid, areasqkm, name) %>% 
  rename(huc8_areasqkm = areasqkm, huc8_name= name, huc8_tnmid = tnmid)
huc8 <- huc8[!duplicated(huc8$huc8_tnmid),]#Remove the duplicated TNMID fields



huc10 <- huc10 %>% 
  select(TNMID, AreaSqKm , Name)%>% 
  rename(huc10_areasqkm = AreaSqKm, huc10_name= Name, huc10_tnmid = TNMID)
huc10 <- huc10[!duplicated(huc10$huc10_tnmid),]#Remove the duplicated TNMID fields



huc12 <- huc12 %>% 
  select(tnmid, areasqkm , name) %>% 
  rename(huc12_areasqkm = areasqkm, huc12_name= name, huc12_tnmid = tnmid)
huc12 <- huc12[!duplicated(huc12$huc12_tnmid),]#Remove the duplicated TNMID fields
#this df needs aditional editting
#Outlet Missisquoi River - HUc12_name this is the same shape, but it actually has two separate tnmid
#Outlet Sutton River and Riviere Sutton are the same shape, but have different HUC 12 names and have different tnmid
#Ruiss Coslett-Riviere Aux Brochets vs Groat Creek are the same shape with different names and tmnid

huc12 <- huc12 %>% 
  filter(huc12_tnmid != "{7964F492-75EA-4AA7-8E77-A96D99348771}",
         huc12_name != "Riviere Sutton",
         huc12_name != "Ruiss Coslett-Riviere Aux Brochets")



#join the huc files to the fish_event file using a spatial join
#each fish survey event will be associated with a huc8, huc10, and huc12 TNMID
sf_use_s2(FALSE)
fish_event_huc_join <- st_join(fish_event, huc8, left = FALSE)
fish_event_huc_join <- st_join(fish_event_huc_join, huc10, left = FALSE)
fish_event_huc_join <- st_join(fish_event_huc_join, huc12, left = FALSE)

fish_event_huc_join <- fish_event_huc_join %>% 
  filter(waterbody == 'lotic')


flowline <- flowline %>% st_zm() %>% 
  filter(FType != 566 & FType != 428 & FType !=420) %>% #remove coastline, pipelines, and underground conduits
  select(-c(VPUID, FDate, Resolution, FType, FCode, MainPath, InNetwork, Visibility, SlopeLenKm, PathLength))


#for the flowline, we want to join the point to the nearest flowline, so we need a different approach.
nearest <- st_nearest_feature(fish_event, flowline) #returns a vector of the index of the flowline that is nearest to each point
dist <- st_distance(fish_event, flowline[nearest,], by_element = TRUE) #get dist from each point to the flowline
dist <- as.numeric(dist)
hist(dist)
fish_event_flowline_join <- cbind(fish_event, st_drop_geometry(flowline)[nearest,]) #join flowline to the fish event based on the index value of the 
fish_event_flowline_join$dist <- dist #add the distence in meters
fish_event_flowline_join <- fish_event_flowline_join %>%  #just keep lotic sites and remove all lotic sites > than 500m from the stream. I looked on GIS at some examples and 500m is about the point where is becomes obvious which site goes with which stream.
  filter(waterbody == "lotic" & dist <500) %>% 
  select(UID, state, date, year, month, waterbody, project, source, NHDPlusID, StreamOrde, StreamLeve, AreaSqKm, TotDASqKm, Slope, MinElevSmo, dist) %>% 
  rename(event_to_flowln_dist_m = dist)
#we will use "MinElevSmo" as the elevation measuremtn of the NHD reach.  It is very similar to the MinElevRaw.

rm(flowline, huc8, huc10, huc12, dist, nearest)

#note that there will be more rows in the HUC dataset because some of the events too far from flowlines were removed.

save(fish_event_flowline_join, file =  "C:/Users/jrogers/Documents/necascFreshwaterBio/model_datafiles/fish_event_flowline_join.RData")
save(fish_event_huc_join, file =  "C:/Users/jrogers/Documents/necascFreshwaterBio/model_datafiles/fish_event_huc_join.RData")

```


Chunk3:
Calcuate average elevation, slopes, land cover etc within each HUC size
```{r}
load("C:/Users/jrogers/Documents/necascFreshwaterBio/model_datafiles/fish_event_huc_join.RData")

```


Preparing the biological data frames:

Chunk4:
1.  presence /absence file.  Only fish presence is currently reported. We want to select only the surveys that were total pick up, and then assign a zero to all fish not observed in each survey. To clarify, all surveys will have a row for every fish and an associated 0 (negative observation) for the fish that were not observed during this survey.

```{r}

#load the fish presence absence data
load('C:/Users/jrogers/Documents/necascFreshwaterBio/spp_data/tidydata/all_fish_presence.RData')

fish <- unique(fish_presence$common_name)

#remove fish that are marine, estuarine, or that have only been observed in 5 or fewer lotic location.
remove <- c("summer flounder","butterfish","king mackerel","northern kingfish",
            "bluefish","winter flounder","striped searobin","northern pipefish",
            "bay anchovy","spot","spotfin mojarra","atlantic tomcod","rainwater killifish",
            "spotfin killifish","crevalle jack","weakfish","northern searobin",
            "sheepshead minnow","atlantic needlefish","naked goby","inland silverside",
            "atlantic menhaden","three-spined stickleback","hogchoker","striped killifish",
            "atlantic silverside","striped bass","mummichog","fourspine stickleback",
            "white perch","shortnose sturgeon","white crappie","lake whitefish","redear sunfish",
            "brook silverside","northern brook lamprey","greater redhorse","guppy", "hickory shad", "western mosquitofish",
            "longnose gar", "northern pearl dace", "gizzard shad", "blackchin shiner", "shorthead redhorse", "tench",
            "lake trout", "atlantic sturgeon", "blackspotted stickleback", "muskellunge", "sunapee trout"
)


fish_presence <- fish_presence %>% 
  filter(!common_name %in% remove,
         !is.na(common_name)) 
  

uid <- unique(fish_presence$UID)
fish <- unique(fish_presence$common_name)

#make a dataframe that has each UID repeated for each fish spp
absence <- data.frame('UID' = rep(uid, each = 78))
absence$common_name <- rep(fish, times = 28457)
#keep only rows in the absence list that are no in the fish_presence list
keep <- anti_join(absence, fish_presence, by = c("UID", "common_name"))
#add additional scientific names to the new absence data frame
scientific_name <- fish_presence %>% 
  select(common_name, scientific_name, genus) %>% 
  unique()
keep <- left_join(keep, scientific_name, by = "common_name")

#add presence absence information
keep$occurrence <- 0
fish_presence$occurrence <- 1

#bind the presence and absence columns together
fish_occurrence <- rbind(fish_presence, keep)
fish_occurrence <- fish_occurrence %>% 
  arrange(UID)

rm(absence, fish_presence, keep, scientific_name)
rm(fish, uid, remove)


#read in method data and keep only the electrofish and total pick up - this will give a list of UIDs that we keep in the presence absence data (won't want to assume all other spp are absent if the survey was a targeted survey, for example). number of passes doenst really matter here because its just if the fish was there, not counts or abundance
load('C:/Users/jrogers/Documents/necascFreshwaterBio/spp_data/tidydata/all_fish_method.RData')
table(method$gear)
table(method$goal)
method <- method %>% 
  filter(goal == "total pick-up",
         gear %in% c("efish_backpack", "efish_barge", "efish_boat", "efish_misc"))

uid <- unique(method$UID)

#filter fish_occurrence data to only include UIDs in the filtered method
fish_occurrence <- fish_occurrence %>% 
  filter(UID %in% uid)

#fish_occurrence df is the file to use for the presence absence analysis.
save(fish_occurrence, file =  "C:/Users/jrogers/Documents/necascFreshwaterBio/model_datafiles/fish_occurrence.RData")

```


Chunk5:
2. prepare fish_count data.  keep only records using total pick up, efish, the first pass, and the ones that listed the reach length so we can calculate count/stream reach length. then rbind to the 'keep' absence dataset abve, which is the absence data for each survey event.  
```{r}


```

Chunk6
3. prepare fish_length data. plot lengths of each fish - if somewhat normal, calcualte the stdev of each to get a measure of variance, the range, mean, max, and min.  For this, i think we can use all surveys because it's not an abundance measure, so we are not going to assume absence anywhere else (ie no need to join with the 'keep' data set).  therefore its ok if the survey was targeted or a different gear type , etc.
```{r}


```




Join the biological data to the hydrologic data using the UID, which was already joined in chunk2:

Chunk7:
1. join the fish presence data to the fish_event_flowline_join, and run a logistic regression using lat, long, total upstream drainage area, slope. 
```{r}
load(file = "C:/Users/jrogers/Documents/necascFreshwaterBio/model_datafiles/fish_event_flowline_join.RData")
load(file =  "C:/Users/jrogers/Documents/necascFreshwaterBio/model_datafiles/fish_occurrence.RData")

fish_occurrence <- fish_occurrence %>% 
  filter(UID %in% fish_event_flowline_join$UID) #remove the UIDs that were removed during the flowline join because they were Lentic or had a dist >500m survey event to nearest stream

logistreg <- left_join(fish_occurrence, fish_event_flowline_join, by = "UID") %>% 
  select(common_name, occurrence, StreamOrde, TotDASqKm, Slope, MinElevSmo,  geometry)

#add columns for lat and long
logistreg <- logistreg %>% 
  mutate(long = unlist(map(logistreg$geometry, 1)),
         lat = unlist(map(logistreg$geometry, 2)))

#sum the NAs in each column
colSums(is.na(logistreg))

hist(logistreg$StreamOrde)
hist(logistreg$TotDASqKm)
hist(logistreg$Slope)
hist(logistreg$lat)
hist(logistreg$long)
hist(logistreg$MinElevSmo)


#remove sites where the slope is less than 0 and where total drainage area is less than 0 because this is impossible
logistreg <- logistreg %>% 
  filter(Slope > 0)
logistreg <- logistreg %>% 
  filter(TotDASqKm > 0)


#add column for log(TotDASqKm) and log(Slope) because these are highly skewed
logistreg$log_Slope <- log(logistreg$Slope)
logistreg$log_TotalDASqK <- log(logistreg$TotDASqKm)

hist(logistreg$log_TotalDASqK)
hist(logistreg$log_Slope) #still not normal

#make correlation matrix for predictors
library(corrplot)
correlation <- cor(logistreg[, c(3, 6, 8, 9, 10, 11)])
corrplot(correlation, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)


#draingage area and stream order are not surprisingly very correlated
#well look at streamorder because its easier to interpret that log drainage area

results <- NULL #initiate dataframe

for (i in unique(logistreg$common_name)) {
  

mdl <- summary(glm(occurrence[logistreg$common_name == i] ~ 
             StreamOrde[logistreg$common_name == i] +  
             Slope[logistreg$common_name == i] + 
             long[logistreg$common_name == i] + 
             lat[logistreg$common_name == i] +
               MinElevSmo[logistreg$common_name == i],
           family = binomial(link = 'logit'), 
           data = logistreg))


#probably wnt to put this in a separate loop so that we can look at the different coef variables... start here next time!!
#the coefients extracted for the table are just a single vairable (stream order) so we woudl want to table for the other coefiencts also.
temp_results <- data.frame("common_name" = i,
                           "presence_number" = nrow(logistreg[logistreg$occurrence == 1 & logistreg$common_name == i,]),
                           "absence_number" = nrow(logistreg[logistreg$occurrence == 0 & logistreg$common_name == i,]),
                      "variable" = "Stream Order",
                      "log_Odds" = round(mdl$coefficients[2,1], 2),
                      "stdev" = round(mdl$coefficients[2 ,2], 2),
                      "p_value" = round(mdl$coefficients[2,4], 2),
                      "odds_ratio" = round(exp(mdl$coefficients[2,1]), 2),
                      "prob" = round(exp(mdl$coefficients[2,1])/ (1+exp(mdl$coefficients[2,1])), 2))
results <- rbind(results, temp_results)



}

hist(logistreg$log_TotalDASqK)
```

Chunk8
2. First prepare the fish count data (like we did in chunk 4 for the presence absence data) and add in the zero data from the presence absence data
keep only records using total pick up, efish, and the ones that listed the reach length so we can calculate count/stream reach length. then rbind to the 'keep' absence dataset abve, which is the absence data for each survey event.  
join the fish count data to the fish_event_flowline_join, and run a zero inflated regression using lat, long, total upstream drainage area, slope. Use the zero values from the fish_occurrence file 

```{r}

#load the fish count data
load('C:/Users/jrogers/Documents/necascFreshwaterBio/spp_data/tidydata/all_fish_count.RData')


#remove fish that are marine, estuarine, or that have only been observed in 5 or fewer lotic location.
remove <- c("summer flounder","butterfish","king mackerel","northern kingfish",
            "bluefish","winter flounder","striped searobin","northern pipefish",
            "bay anchovy","spot","spotfin mojarra","atlantic tomcod","rainwater killifish",
            "spotfin killifish","crevalle jack","weakfish","northern searobin",
            "sheepshead minnow","atlantic needlefish","naked goby","inland silverside",
            "atlantic menhaden","three-spined stickleback","hogchoker","striped killifish",
            "atlantic silverside","striped bass","mummichog","fourspine stickleback",
            "white perch","shortnose sturgeon","white crappie","lake whitefish","redear sunfish",
            "brook silverside","northern brook lamprey","greater redhorse","guppy", "hickory shad", "western mosquitofish",
            "longnose gar", "northern pearl dace", "gizzard shad", "blackchin shiner", "shorthead redhorse", "tench",
            "lake trout", "atlantic sturgeon", "blackspotted stickleback", "muskellunge", "sunapee trout"
)


#load in the fish occurrence file just to extract the 0 occurence data, and to extract the UIDs that were already editted in be total pick up and efish only
load(file =  "C:/Users/jrogers/Documents/necascFreshwaterBio/model_datafiles/fish_occurrence.RData")
uid <- fish_occurrence$UID


#filter the common names, the UIDs, we will keep all runs, because removing all but the first run removes all of ME and too many observations.
fish_count <- fish_count %>% 
  filter(!common_name %in% remove,
         !is.na(common_name),
         UID %in% uid)



#add zero data
#we cant just take the zeros from the fish_occurrence dataframe.  This is because the fish_occurrence dataframe marked 'presnet' if the fish spp was observed regardless of run number.  The count data only used the first run. Therefore, there will be some fish that were 'present' but not 'counted' and therefore we will be short zeros for all spp observed during runs 2 and greater. well used the same method we used for the fish_occurrence data

fish <- unique(fish_count$common_name)
uid <- unique(fish_count$UID)
#make a dataframe that has each UID repeated for each fish spp
absence <- data.frame('UID' = rep(uid, each = length(fish)))
absence$common_name <- rep(fish, times = length(uid))
#keep only rows in the absence list that are not in the fish_count list
keep <- anti_join(absence, fish_count, by = c("UID", "common_name"))
#add additional scientific names to the new absence data frame
scientific_name <- fish_count %>% 
  select(common_name, scientific_name, genus) %>% 
  unique()
keep <- left_join(keep, scientific_name, by = "common_name")

#add absence information
keep$count <- 0
keep$run_num <- 1


#bind the presence and absence columns together
fish_count_with_zeros <- rbind(fish_count, keep)
fish_count_with_zeros <- fish_count_with_zeros %>% 
  arrange(UID)





#join the method data because we will include reach length as a predictor variable
load('C:/Users/jrogers/Documents/necascFreshwaterBio/spp_data/tidydata/all_fish_method.RData')
colSums(is.na(method))
method <- method %>% 
  select(-daylight, -target, -Comments, -Data_Comments)
fish_count_with_zeros <- left_join(fish_count_with_zeros, method, by = "UID")


#fish_count_with_zeros df is the file to use for the zero inflated poisson regression analysis and for the clustering sites based on abundance.
save(fish_count_with_zeros, file =  "C:/Users/jrogers/Documents/necascFreshwaterBio/model_datafiles/fish_count_with_zeros.RData") 


 






load(file = "C:/Users/jrogers/Documents/necascFreshwaterBio/model_datafiles/fish_event_flowline_join.RData")



countmdl <- left_join(fish_count_with_zeros, fish_event_flowline_join, by = "UID") %>% 
  select(common_name, count, StreamOrde, TotalDASqK, Slope, geometry) %>% 
  filter(!is.na(StreamOrde))#remove the UIDs that were removed during the flowline join because they were Lentic or had a dist >500m survey event to nearest stream

#add columns for lat and long
countmdl <- countmdl %>% 
  mutate(long = unlist(map(countmdl$geometry, 1)),
         lat = unlist(map(countmdl$geometry, 2)))

#sum the NAs in each column
colSums(is.na(countmdl))


#remove sites where the slope is less than 0 and where total drainage area is less than 0 because this is impossible
countmdl <- countmdl %>% 
  filter(Slope > 0)
countmdl <- countmdl %>% 
  filter(TotalDASqK > 0)


summary(mdl <- lm(count ~ lat, data = countmdl[countmdl$common_name == "fallfish",]))


```




Chunk9
3. Prepare the fish length data (like we did in chunk 4 for the presence absence data) 
join the fish length data to the fish_event_flowline_join, calucate the variance of lengths at each site, and run a linear regression using lat, long, total upstream drainage area, slope. In this model, we can use all of the data, regardless of reach lenght and total pick up and gear.

```{r}

load('C:/Users/jrogers/Documents/necascFreshwaterBio/spp_data/tidydata/all_fish_size.RData')
load(file = "C:/Users/jrogers/Documents/necascFreshwaterBio/model_datafiles/fish_event_flowline_join.RData")

fish <- unique(fish_size$common_name)

#remove fish that are marine, estuarine, or that have only been observed in 5 or fewer lotic location.
remove <- c("summer flounder","butterfish","king mackerel","northern kingfish",
            "bluefish","winter flounder","striped searobin","northern pipefish",
            "bay anchovy","spot","spotfin mojarra","atlantic tomcod","rainwater killifish",
            "spotfin killifish","crevalle jack","weakfish","northern searobin",
            "sheepshead minnow","atlantic needlefish","naked goby","inland silverside",
            "atlantic menhaden","three-spined stickleback","hogchoker","striped killifish",
            "atlantic silverside","striped bass","mummichog","fourspine stickleback",
            "white perch","shortnose sturgeon","white crappie","lake whitefish","redear sunfish",
            "brook silverside","northern brook lamprey","greater redhorse","guppy", "hickory shad", "western mosquitofish",
            "longnose gar", "northern pearl dace", "gizzard shad", "blackchin shiner", "shorthead redhorse", "tench",
            "lake trout", "atlantic sturgeon", "blackspotted stickleback", "muskellunge", "sunapee trout"
)

fish_size <- fish_size %>% 
  filter(!common_name %in% remove) %>% 
  filter(!is.na(common_name))



#fix observations that are clearly erroneous 

fish_size$length_mm[fish_size$length_mm == 110105] <- 110 #this makes sense based on the weight, and I assume the accidentally typed in two lengths in a row 
fish_size$length_mm[fish_size$length_mm == 5200] <- 520 #well just assume they added an extra zero
fish_size$length_mm[fish_size$length_mm == 880 & fish_size$common_name == "brook trout"] <- 88 #well just assume they added an extra zero, which makes sence based on the weigth
fish_size$length_mm[fish_size$length_mm == 7474] <- 74 #well just assume they typed in the number twice by accident

ggplot(data = fish_size, aes(x = length_mm))+
  geom_histogram()



#filter for the UIDs in the 'fish_event_flowline_join$UID')' to remove the UIDs that were removed during the flowline join because they were Lentic or had a dist >500m survey event
fish_size <- left_join(fish_size, fish_event_flowline_join, by = "UID")
colSums(is.na(fish_size))
fish_size <- fish_size %>% 
  filter(!is.na(NHDPlusID))


#plot the lengths of each fish as a histogram.
for( i in 1:length(unique(fish_size$common_name))){
  
  ggplot()+
    geom_histogram(data = fish_size[fish_size$common_name == unique(fish_size$common_name)[i], ], aes(x = length_mm))+
    ggtitle(label = paste(unique(fish_size$common_name)[i], (unique(fish_size$scientific_name)[i]), sep = ", "))
  
  ggsave(
    filename = paste("tmpfigures/fish_length_plots/", unique(fish_size$common_name)[i], ".png", sep = ""),
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 150
  )
  
  print(i)
} 

 

#calculate variance for each spp by UID. First need to remove outliers so ensure normal dist. cant do this for the bimodal distributions (anadromous spp)


```
