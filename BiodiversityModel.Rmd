---
title: "Biodiversity Model"
author: "Jenny Rogers"
date: '2022-09-22'
output: html_document
---




```{r}
library(tidyverse)
library(sf)
library(lubridate)
library(corrplot)
library(caret)
library(readxl)


```


In this first chunk, read in files: 

```{r}
#fish data
load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_datafiles/fish_occurrence.RData")
load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_datafiles/fish_count_with_zeros.RData")
fish_shp <- st_read("C:/Users/jenrogers/Documents/necascFreshwaterBio/SpatialData/sppdata/all_fish_event.shp")

#fish event and hydrography join
load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_datafiles/fish_event_huc_join.RData")
load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_datafiles/fish_event_flowline_join.RData")
load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_datafiles/fish_event_flowlineV2_join.RData")


#watershed shape files
huc8 <- st_read("C:/Users/jenrogers/Documents/necascFreshwaterBio/SpatialData/NHDplus/WBDHU8/WBDHU8_NE.shp")

#load new england state data
states <- st_read("C:/Users/jenrogers/Documents/necascFreshwaterBio/SpatialData/newenglandshape/NEWENGLAND_POLY.shp")



#tidied covariates 
load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_datafiles/model_covariates.RData")
load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_datafiles/model_covariates_byhuc12.RData")

#fish traits
load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_datafiles/fish_traits.RData")
temperature <- read_xlsx("C:/Users/jenrogers/Documents/necascFreshwaterBio/spp_data/thermalpref_origin_tolerance.xlsx",
                  sheet = 1,
                  range = cell_cols("A:G")) %>% 
  pivot_longer(2:7, names_to = "state", values_to = "tmp")
origin <- read_xlsx("C:/Users/jenrogers/Documents/necascFreshwaterBio/spp_data/thermalpref_origin_tolerance.xlsx",
                  sheet = 2,
                  range = cell_cols("A:G"))%>% 
  pivot_longer(2:7, names_to = "state", values_to = "origin")

```






first make a proportional abundance column and then join the count data to the event data and to all the covariates
Then model relative abundance with a zero-inflated binomial model from the glmmTMB package
```{r}
#want to try this model at the HUC12 scale
# will need to average the proporation abundance by the huc12tnmid
# will need to average all the covariates (except the Temperautre and dams which are already at the huc12 scale, by huc12tnmid)

# library(glmmTMB)
# countsbyhuc <- left_join(fish_count_with_zeros, fish_event_huc_join, by = "UID") %>% 
#   group_by(huc12_tnmid, huc12_name) %>% 
#   mutate(totalcount = sum(count)) %>% 
#   ungroup()  %>% 
#   group_by(huc12_tnmid, huc12_name, common_name) %>% 
#   mutate(huc12sppcount = sum(count),
#          propabun = (huc12sppcount / totalcount)) %>%
#   ungroup() %>% 
#   select(huc12_tnmid, huc12_name, huc12sppcount, totalcount, propabun, common_name, gear)%>% 
#   unique() %>% 
#   filter(common_name == "redfin pickerel") 
# 
# hist(countsbyhuc$propabun)
# 
# # the observed proportional abundance
# fish_shp <- left_join(fish_shp, data.frame(fish_event_huc_join), 
#                       by = c("UID", "state", "date", "year", "month", "waterbody", "project", "source"))
# 
# shp <- left_join(fish_shp, countsbyhuc, by = c("huc12_tnmid", "huc12_name")) %>%
#   filter(!is.na(propabun)) %>%
#   mutate(occurrence = ifelse(huc12sppcount>0, 1, 0))
# ggplot(data = shp)+
#   geom_sf(aes(fill = as.factor(propabun), size = propabun), pch = 21, col = "black")
# 
# fishcovariates_byhuc12 <- fishcovariates_byhuc12[complete.cases(fishcovariates_byhuc12),]
# test <- fishcovariates_byhuc12[,c(3:34)]
# test <- data.frame(scale(test))
# 
# fishcovariates_byhuc12 <- cbind((fishcovariates_byhuc12)[,c(1,2)], test)
# 
# 
# #join the countsbyhuc to the tidying covariates, fishcovariates
# dat <- left_join(countsbyhuc, fishcovariates_byhuc12, by = c("huc12_tnmid", "huc12_name"))
# 
# 
# dat <- dat %>% 
#   mutate(occurrence = ifelse(huc12sppcount>0, 1, 0)) %>% 
#   select(huc12_tnmid, huc12_name, common_name, occurrence, propabun, lat, long, 8:39)
# 
# 
# #plot of variables vs proportional abundance
# dat$occurrence <- as.factor(dat$occurrence)
# ggplot(data = dat, mapping = aes(x = occurrence, y = pctForest_ws))+
#   geom_violin()+
#   geom_boxplot(width = 0.1)+
#   geom_smooth(method = "lm")+
#     theme(panel.border = element_rect(colour = "black", fill = NA),
#           panel.grid.major = element_blank(),
#           panel.grid.minor = element_blank(),
#           panel.background = element_blank())+
#   labs(title = "brook trout")
# 
# 
# #histogram of relative abundance
# ggplot(data = dat, mapping = aes(x = propabun))+
#   geom_histogram()
# #histogram of relative abundance without the zeros so we can see the other data
# ggplot(data = dat[dat$occurrence ==1,], mapping = aes(x = propabun))+
#   geom_histogram()
# 
# # #map of observed relative abundance - need to join to the shapefile with UID
# rel_abundance <- left_join(fish_shp, dat, by = c("huc12_tnmid", "huc12_name"))
# ggplot(data = rel_abundance)+
#   geom_sf(aes(fill = as.factor(occurrence), size = propabun), pch = 21, color = "black")
# 
# 
# 
# #global model
# mdl <- glmmTMB(propabun ~
#                  annual_mean_summer_temp + 
#                  BFI_HIST + 
#                  LO7Q1DT_HIST +
#                  W95_HIST + 
#                  BFIWs +   
#                  WtDepWs + 
#                  PctOw_Ws +  
#                  PctImp_Ws +  
#                  pctAg_Ws + 
#                  pctWetland_Cat + 
#                  logMJJA_HIST + 
#                  logRdCrsCat + 
#                  logPctOw_Cat +
#                  huc12_damden_sqkm +
#                  huc8_damcount,
#                data = dat,
#                ziformula = ~lat + long + ElevCat + logWsAreaSqKm,
#                family = beta_family())
# summary(mdl)
# saveRDS(mdl, paste("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_objects/propabun_", unique(dat$common_name), ".rds", sep = ""))
# 


```


Proportional abundance at the stream reach scale
```{r}
#models at the stream reach scale
library(glmmTMB)

#filter the fish names to be only those that we agreed as a group we would include
#we also excluded bowfin, white catfish, channel catfish, round whitefish, and walleye becuase when splitting into testing and trainng data, there was not enough 'present' observations and it was thowing a model errow
fish_count_with_zeros_filtered <- fish_count_with_zeros %>% 
  filter(common_name %in% c("american eel", "white perch", "rosyside dace",  
                            "spotfin shiner", "mimic shiner", "finescale dace", "american brook lamprey", 
                            "eastern silvery minnow", "rosyface shiner", "cutlips minnow", "green sunfish", 
                            "brook stickleback", "common carp", "central mudminnow", "northern pike", "bridle shiner", 
                            "swamp darter", "lake chub", "banded killifish", "margined madtom", "burbot", "black crappie", 
                            "spottail shiner", "redbelly dace", "creek chubsucker", "banded sunfish", "fathead minnow", 
                            "bluntnose minnow", "redbreast sunfish", "rock bass", "rainbow trout", "longnose sucker", 
                            "smallmouth bass", "yellow bullhead", "redfin pickerel", "yellow perch", "brown bullhead", 
                            "atlantic salmon", "golden shiner", "chain pickerel", "bluegill", "brown trout", "tessellated darter", 
                            "largemouth bass", "fallfish", "common shiner", "creek chub", "pumpkinseed", "slimy sculpin", 
                            "longnose dace", "white sucker", "eastern blacknose dace", "brook trout"))

counts <- fish_count_with_zeros_filtered %>%
  filter(gear == "efish_backpack") %>% 
  group_by(UID) %>% 
  mutate(totalcount = sum(count)) %>% 
  ungroup() %>% 
  mutate(propabun = (count / totalcount)) %>% 
  select(UID, count, totalcount, propabun, common_name, gear, reach_length_m) %>% 
  mutate(abund_km = count / (reach_length_m) *1000) %>% 
  filter(common_name == "white sucker")

ggplot(data = counts, aes(x = propabun))+
  geom_histogram(color = "black", fill = "grey50")+
  theme(
    panel.border = element_rect(color = "black", fill = NA),
    panel.grid = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.title = element_text(size = 15),
    axis.text = element_text(size = 13))+
  labs(x = "Proportional Abundance",
       y = "Count")
ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/suckercounts.png",
    plot = last_plot(),
    width = 18,
    height = 9,
    units = "cm",
    dpi = 300
  )
      

#plot the observed proportional abundance
shp <- left_join(fish_shp, counts, by = "UID") %>%
  filter(!is.na(propabun)) %>%
  mutate(occurrence = ifelse(count>0, 1, 0))
ggplot(data = shp)+
  geom_sf(aes(color = propabun))

fishcovariates <- fishcovariates[complete.cases(fishcovariates),]
test <- fishcovariates[,c(2:3, 9:38)]
test <- data.frame(scale(test))

fishcovariates <- cbind((fishcovariates)[,c(1, 4:8)], test)


#join the counts to the tidying covariates, fishcovariates
dat <- left_join(counts, fishcovariates, by = "UID")


dat <- dat %>% 
  mutate(occurrence = ifelse(count>0, 1, 0)) %>% 
  select(UID, common_name, occurrence, propabun, state, huc8_name, 14:45)


#plot of variables vs proportional abundance
dat$occurrence <- as.factor(dat$occurrence)
ggplot(data = dat, mapping = aes(x = occurrence, y = W95_HIST))+
  geom_violin(lwd = 1, fill = "azure1")+
  geom_boxplot(width = 0.1, lwd = .5, color = "grey30", fill = "cornflowerblue")+
  geom_smooth(method = "lm")+
    theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          axis.title = element_text(size = 15),
          axis.text = element_text(size = 11))+
  labs(title = "white sucker",
       x = "Presence / Absence",
       y = "Winter Storms (#)")
ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/suckercounts.png",
    plot = last_plot(),
    width = 12,
    height = 10,
    units = "cm",
    dpi = 300
  )

#histogram of relative abundance
# ggplot(data = dat, mapping = aes(x = propabun))+
#   geom_histogram()
# #histogram of relative abundance without the zeros so we can see the other data
# ggplot(data = dat[dat$occurrence ==1,], mapping = aes(x = propabun))+
#   geom_histogram()
# 
# #map of observed relative abundance - need to join to the shapefile with UID
# rel_abundance <- left_join(fish_shp, dat, by ="UID") 
# ggplot(data = rel_abundance)+
#   geom_sf(aes(fill = as.factor(occurrence), size = propabun), pch = 21, color = "black")


#two options to further reduce the variable list:

# PCA to combine all the variables used in the conditional model (or both models?) need to do this

#simple binomial models to identify which variables are not related to the outcome
# mdl <- glmmTMB(propabun ~ huc8_damcount,
#                data = dat,
#                family = "binomial")
# summary(mdl)

dat$propabun[dat$propabun == 1] <- 0.99
dat <- dat %>% 
  filter(!is.na(lat))

#set aside 20% for validation and put 80% into the calibration dataset
n_obs <- nrow(dat)
permuted_rows <- sample(n_obs)
dat <- dat[permuted_rows,]
split <- round(n_obs * 0.8)
set.seed(3223)
train <- dat[1:split, ]
test <- dat[(split+1):n_obs, ]


#global model
mdl <- glmmTMB(propabun ~
                 annual_mean_summer_temp + 
                 BFI_HIST + 
                 LO7Q1DT_HIST +
                 W95_HIST + 
                 BFIWs +   
                 WtDepWs + 
                 PctOw_Ws +  
                 PctImp_Ws +  
                 pctAg_Ws + 
                 pctWetland_Cat + 
                 logMJJA_HIST + 
                 logRdCrsCat + 
                 logPctOw_Cat +
                 huc12_damden_sqkm +
                 huc8_damcount +
                 lat +
                 long +
                 ElevCat + 
                 logWsAreaSqKm,
                data = train,
               ziformula = ~annual_mean_summer_temp + 
                 BFI_HIST + 
                 LO7Q1DT_HIST +
                 W95_HIST + 
                 BFIWs +   
                 WtDepWs + 
                 PctOw_Ws +  
                 PctImp_Ws +  
                 pctAg_Ws + 
                 pctWetland_Cat + 
                 logMJJA_HIST + 
                 logRdCrsCat + 
                 logPctOw_Cat +
                 huc12_damden_sqkm +
                 huc8_damcount +
                 lat +
                 long +
                 ElevCat + 
                 logWsAreaSqKm,
               family = beta_family())

summary(mdl)
saveRDS(mdl, paste("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_objects/propabun_", unique(dat$common_name), ".rds", sep = ""))

#make a table of the model resuls

results1 <- 
  data.frame(
    "estimate" = summary(mdl)$coefficients$cond[,1],
    "std_er" = summary(mdl)$coefficients$cond[,2],
    "p_val" = summary(mdl)$coefficients$cond[,4],
    "variable" = rownames(summary(mdl)$coefficients$cond),
    "model" = "conditional")

results2 <- 
  data.frame(
    "estimate" = summary(mdl)$coefficients$zi[,1],
    "std_er" = summary(mdl)$coefficients$zi[,2],
    "p_val" = summary(mdl)$coefficients$zi[,4],
    "variable" = rownames(summary(mdl)$coefficients$zi),
    "model" = "zeroinfla")

results <- rbind(results1, results2)
results$common_name <- unique(dat$common_name)

#use model to predict on testing data
predict_resp <- predict(mdl, test, type = 'response') #the predicted value

predict_zer <- predict(mdl, test, type = 'zprob') #the probability of a zero

#compare the predicted zeros to the actual zeros, the prediction prop abund to the actual prop abun
#The last two are ranked predicted prop abund to the ranked actual prop abund. Even if the raw magnitudes differ, we would still want a positive relatiomship between the ranked values, so this is what I used to validate in the plot with r2 value
compare <- data.frame(
  "common_name" = test$common_name,
  "occurrence" = factor(test$occurrence),
  "propabun" = round(test$propabun, 2),
  "pred_occurrence" = factor(ifelse(predict_zer > 0.7, 0, 1), levels = levels(factor(test$occurrence))),
  "pred_propabun" = round(predict_resp, 2),
  "rank_propabun" = as.numeric(ordered(round(test$propabun, 2))),
  "rank_pred_propabun" = as.numeric(ordered(round(predict_resp, 2)))
)

compare <- compare %>% 
  mutate(tmp = (pred_propabun - propabun)^2,
         tmp2 = (sum(tmp, na.rm = T))/nrow(compare),
         RMSE = sqrt(tmp2))

compare <- na.omit(compare)
r2_probabun <- cor(compare$propabun,  compare$pred_propabun)
ggplot(data = compare, aes(x = propabun, y = pred_propabun))+
  geom_jitter(alpha = 0.1, size = 3)+
  geom_smooth(method = "lm")+
  labs(x = "Testing Data Prop Abun", y = "Predicted Prop Abun")+
  annotate("text",x=.5,y=.2,label=r2_probabun,parse=TRUE, color = "red", size = 5)

#validate the ranked prop abund values
r2_rank_propabun <- cor(compare$rank_propabun,  compare$rank_pred_propabun)

ggplot(data = compare, aes(x = rank_propabun, y = rank_pred_propabun))+
  geom_jitter(alpha = 0.1, size = 3)+
  geom_smooth(method = "lm")+
  labs(x = "Testing Data Prop Abun Rank", y = "Predicted Prop Abun Rank")+
  annotate("text",x=20,y=5,label=r2_rank_propabun,parse=TRUE, color = "red", size = 5)
ggsave(
    filename = paste("tmpfigures/propabun_rank_compare/" , unique(train$common_name), ".png", sep = ""),
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 300
  )

val_prop_abun <- data.frame(
  "common_name" = unique(train$common_name),
  "r2_propabun" = r2_probabun,
  "r2_rank_propabun" = r2_rank_propabun,
  "RMSE" = unique(compare$RMSE)
  
)

#validations for the predicted occurrence vs the actual occurrence
compare$pred_occurrence <- factor(compare$pred_occurrence, levels = c(1,0))
compare$occurrence <- factor(compare$occurrence, levels = c(1,0))
cm <- confusionMatrix(reference = compare$occurrence, data = compare$pred_occurrence)

val_zero_prob <- data.frame(
  "common_name" = unique(train$common_name),
  "test_dat_pres" = nrow(test[test$occurrence == 1,]),
  "test_dat_abs" = nrow(test[test$occurrence == 0,]),
  "train_dat_pres" = nrow(train[train$occurrence == 1, ]),
  "train_dat_abs" = nrow(train[train$occurrence == 0, ]),
  "accuracy" = round(cm$overall[1], 2),
  "sensitivity" = round(cm$byClass[1], 2),
  "Specificity" = round(cm$byClass[2], 2),
  "Pos Pred Value" = round(cm$byClass[3], 2),
  "Neg Pred Value" = round(cm$byClass[4], 2)
)


#Start the for loop here

for (i in 2:length(unique(fish_count_with_zeros_filtered$common_name))) { #start with 2 bc we used white sucker as the started spp above
  


counts <- fish_count_with_zeros_filtered %>%
  filter(gear == "efish_backpack") %>% 
  group_by(UID) %>% 
  mutate(totalcount = sum(count)) %>% 
  ungroup() %>% 
  mutate(propabun = (count / totalcount)) %>% 
  select(UID, count, totalcount, propabun, common_name, gear, reach_length_m) %>% 
  mutate(abund_km = count / (reach_length_m) *1000) %>% 
  filter(common_name == unique(fish_count_with_zeros_filtered$common_name)[i])


#join the counts to the tidying covariates, fishcovariates
dat <- left_join(counts, fishcovariates, by = "UID")
dat$occurrence <- ifelse(dat$count>0, 1,0)
dat <- dat[complete.cases(dat),]
dat$propabun[dat$propabun == 1] <- 0.99
dat <- dat %>% 
  filter(!is.na(lat))

#set aside 20% for validation and put 80% into the calibration dataset
n_obs <- nrow(dat)
permuted_rows <- sample(n_obs)
dat <- dat[permuted_rows,]
split <- round(n_obs * 0.8)
set.seed(32435)
train <- dat[1:split, ]
test <- dat[(split+1):n_obs, ]

#global model
mdl <- glmmTMB(propabun ~
                 annual_mean_summer_temp + 
                 BFI_HIST + 
                 LO7Q1DT_HIST +
                 W95_HIST + 
                 BFIWs +   
                 WtDepWs + 
                 PctOw_Ws +  
                 PctImp_Ws +  
                 pctAg_Ws + 
                 pctWetland_Cat + 
                 logMJJA_HIST + 
                 logRdCrsCat + 
                 logPctOw_Cat +
                 huc12_damden_sqkm +
                 huc8_damcount +
                 lat +
                 long +
                 ElevCat + 
                 logWsAreaSqKm,
                data = train,
               ziformula = ~annual_mean_summer_temp + 
                 BFI_HIST + 
                 LO7Q1DT_HIST +
                 W95_HIST + 
                 BFIWs +   
                 WtDepWs + 
                 PctOw_Ws +  
                 PctImp_Ws +  
                 pctAg_Ws + 
                 pctWetland_Cat + 
                 logMJJA_HIST + 
                 logRdCrsCat + 
                 logPctOw_Cat +
                 huc12_damden_sqkm +
                 huc8_damcount +
                 lat +
                 long +
                 ElevCat + 
                 logWsAreaSqKm,
               family = beta_family())

saveRDS(mdl, paste("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_objects/propabun_", unique(fish_count_with_zeros_filtered$common_name)[i], ".rds", sep = ""))

#make a table of the model resuls


results1 <- 
  data.frame(
    "estimate" = summary(mdl)$coefficients$cond[,1],
    "std_er" = summary(mdl)$coefficients$cond[,2],
    "p_val" = summary(mdl)$coefficients$cond[,4],
    "variable" = rownames(summary(mdl)$coefficients$cond),
    "model" = "conditional")

results2 <- 
  data.frame(
    "estimate" = summary(mdl)$coefficients$zi[,1],
    "std_er" = summary(mdl)$coefficients$zi[,2],
    "p_val" = summary(mdl)$coefficients$zi[,4],
    "variable" = rownames(summary(mdl)$coefficients$zi),
    "model" = "zeroinfla")

tmp <- rbind(results1, results2)
tmp$common_name <- unique(fish_count_with_zeros_filtered$common_name)[i]



results <- rbind(results, tmp)

#use model to predict on testing data
predict_resp <- predict(mdl, test, type = 'response') #the predicted value

predict_zer <- predict(mdl, test, type = 'zprob') #the probability of a zero

compare <- data.frame(
  "common_name" = rep(unique(train$common_name), nrow(test)),
  "occurrence" = factor(test$occurrence),
  "propabun" = round(test$propabun, 2),
  "pred_occurrence" = factor(ifelse(predict_zer > 0.7, 0, 1), levels = levels(factor(test$occurrence))),
  "pred_propabun" = round(predict_resp, 2),
  "rank_propabun" = as.numeric(ordered(round(test$propabun, 2))),
  "rank_pred_propabun" = as.numeric(ordered(round(predict_resp, 2)))
)

compare <- compare %>% 
  mutate(tmp = (pred_propabun - propabun)^2,
         tmp2 = (sum(tmp, na.rm = T))/nrow(compare),
         RMSE = sqrt(tmp2))

r2_propabun <- cor(compare$propabun,  compare$pred_propabun)

ggplot(data = compare, aes(x = propabun, y = pred_propabun))+
  geom_jitter(alpha = 0.1, size = 3)+
  geom_smooth(method = "lm")+
  labs(x = "Testing Data Prop Abun Rank", y = "Predicted Prop Abun Rank")+
  annotate("text",x=20,y=5,label=r2_propabun,parse=TRUE, color = "red", size = 5)

r2_rank_propabun <- cor(compare$rank_propabun,  compare$rank_pred_propabun)

ggplot(data = compare, aes(x = rank_propabun, y = rank_pred_propabun))+
  geom_jitter(alpha = 0.1, size = 3)+
  geom_smooth(method = "lm")+
  labs(x = "Testing Data Prop Abun Rank", y = "Predicted Prop Abun Rank")+
  annotate("text",x=20,y=5,label=r2_rank_propabun,parse=TRUE, color = "red", size = 5)
ggsave(
    filename = paste("tmpfigures/propabun_rank_compare/" , unique(train$common_name), ".png", sep = ""),
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 300
  )

val_prop_abun2 <- data.frame(
  "common_name" = unique(train$common_name),
  "r2_propabun" = r2_propabun,
  "r2_rank_propabun" = r2_rank_propabun,
  "RMSE" = unique(compare$RMSE)
  
)

val_prop_abun <- rbind(val_prop_abun, val_prop_abun2)

compare$pred_occurrence <- factor(compare$pred_occurrence, levels = c(1,0))
compare$occurrence <- factor(compare$occurrence, levels = c(1,0))

cm <- confusionMatrix(reference = compare$occurrence, data = compare$pred_occurrence)

val2 <- data.frame(
  "common_name" = unique(train$common_name),
  "test_dat_pres" = nrow(test[test$occurrence == 1,]),
  "test_dat_abs" = nrow(test[test$occurrence == 0,]),
  "train_dat_pres" = nrow(train[train$occurrence == 1, ]),
  "train_dat_abs" = nrow(train[train$occurrence == 0, ]),
  "accuracy" = round(cm$overall[1], 2),
  "sensitivity" = round(cm$byClass[1], 2),
  "Specificity" = round(cm$byClass[2], 2),
  "Pos Pred Value" = round(cm$byClass[3], 2),
  "Neg Pred Value" = round(cm$byClass[4], 2)
)
val_zero_prob <- rbind(val_zero_prob, val2)


print(unique(fish_count_with_zeros_filtered$common_name)[i])

}



#cbind the two validation dfs so we can write a single csv
prop_abun_validation <- cbind(val_zero_prob, val_prop_abun)
prop_abun_validation <- prop_abun_validation %>% 
  select(-11) %>% 
  arrange(common_name)

write.csv(val_zero_prob, file = "tmpfigures/val_zero_prob.csv")
write.csv(prop_abun_validation, file = "tmpfigures/prop_abun_validation.csv")

#all the species models (53 total) had model convergence

cond <- results %>% 
  filter(model == "conditional")



zer <- results %>% 
  filter(model == "zeroinfla") %>% 
  mutate(estimate = -estimate)


#conditional results: calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results2 <- cond %>% 
  mutate(CIlow = estimate - (1.96*std_er),
         CIhigh = estimate + (1.96*std_er),
         OR = round(exp(estimate), 2),
         ORCIlow = round(exp(CIlow), 2),
         ORCIhigh = round(exp(CIhigh), 2)) %>% 
  arrange(common_name) %>% 
  filter(variable != "(Intercept)") %>% 
  select(common_name, variable, OR, ORCIlow, ORCIhigh, p_val) %>% 
  mutate(OR = ifelse(p_val<0.001, paste(OR, "***", sep = ""),
                     ifelse(p_val < 0.01 & p_val > 0.001, paste(OR, "**", sep = ""),
                            ifelse(p_val < 0.1 & p_val > 0.01, paste(OR, "*", sep = ""),
                                   OR)))) %>% 
  filter(p_val <0.1)
  
rownames(results2) <- NULL

#rename variables to make more interpretable
results2$variable[results2$variable == "annual_mean_summer_temp"] <- "mean summer temp"
results2$variable[results2$variable == "huc12_damden_sqkm"] <- "dam density"
results2$variable[results2$variable == "BFI_HIST"] <- "baseflow index"
results2$variable[results2$variable == "LO7Q1DT_HIST"] <- "low flow date"
results2$variable[results2$variable == "W95_HIST"] <- "number of winter floods"
results2$variable[results2$variable == "logMJJA_HIST"] <- "summer flow"
results2$variable[results2$variable == "lat"] <- "latitude"
results2$variable[results2$variable == "long"] <- "longitude"
results2$variable[results2$variable == "ElevCat"] <- "elevation"
results2$variable[results2$variable == "logWsAreaSqKm"] <- "watershed area"
results2$variable[results2$variable == "huc8_damcount"] <- "dam count"


write.csv(results2, file = "tmpfigures/propabun_results.csv")
prop_abun_results <- read.csv("tmpfigures/propabun_results.csv")


#zero inflation results: calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results_zer <- zer %>% 
  mutate(CIlow = estimate - (1.96*std_er),
         CIhigh = estimate + (1.96*std_er),
         OR = round(exp(estimate), 2),
         ORCIlow = round(exp(CIlow), 2),
         ORCIhigh = round(exp(CIhigh), 2)) %>% 
  arrange(common_name) %>% 
  filter(variable != "(Intercept)") %>% 
  select(common_name, variable, OR, ORCIlow, ORCIhigh, p_val) %>% 
  mutate(OR = ifelse(p_val<0.001, paste(OR, "***", sep = ""),
                     ifelse(p_val < 0.01 & p_val > 0.001, paste(OR, "**", sep = ""),
                            ifelse(p_val < 0.1 & p_val > 0.01, paste(OR, "*", sep = ""),
                                   OR)))) %>% 
  filter(p_val <0.1)
  
rownames(results_zer) <- NULL

#rename variables to make more interpretable
results_zer$variable[results_zer$variable == "annual_mean_summer_temp"] <- "mean summer temp"
results_zer$variable[results_zer$variable == "huc12_damden_sqkm"] <- "dam density"
results_zer$variable[results_zer$variable == "BFI_HIST"] <- "baseflow index"
results_zer$variable[results_zer$variable == "LO7Q1DT_HIST"] <- "low flow date"
results_zer$variable[results_zer$variable == "W95_HIST"] <- "number of winter floods"
results_zer$variable[results_zer$variable == "logMJJA_HIST"] <- "summer flow"
results_zer$variable[results_zer$variable == "lat"] <- "latitude"
results_zer$variable[results_zer$variable == "long"] <- "longitude"
results_zer$variable[results_zer$variable == "ElevCat"] <- "elevation"
results_zer$variable[results_zer$variable == "logWsAreaSqKm"] <- "watershed area"
results_zer$variable[results_zer$variable == "huc8_damcount"] <- "dam count"


write.csv(results_zer, file = "tmpfigures/zeroinfla_results.csv")




#make plots for manuscript one that show the model performance: a series of histograms that show the counts of accuracy, sensitivity, specificity
prop_abun_validation <- read.csv("tmpfigures/prop_abun_validation.csv")
df <- prop_abun_validation %>% 
  select(common_name, accuracy, sensitivity, Specificity) %>% 
  rename("Accuracy" = "accuracy", "Sensitivity" = "sensitivity") %>% 
  pivot_longer(2:4, names_to = "metric", values_to = "value") 
ggplot(data = df, aes(x = value))+
  geom_histogram(bins = 10, fill = "grey", color = "black")+
  facet_wrap(~metric)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_line(color = "grey", linewidth = 0.1),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 12),
        title = element_text(size = 12))+
  labs(x = "Proportion", y = "Count")+
  ggtitle("A")
ggsave(
    filename = "tmpfigures/paper1/validationhistogram_zero.png",
    plot = last_plot(),
    width = 14,
    height = 5,
    units = "cm",
    dpi = 300)

#histogram of the ranked prop abund correlations
ggplot(data = prop_abun_validation, aes(x = r2_rank_propabun))+
  geom_histogram(bins = 15, fill = "grey", color = "black")+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_line(color = "grey", linewidth = 0.1),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 12),
        title = element_text(size = 12))+
  labs(x = "Correlation", y = "Count")+
  scale_y_continuous(limits = c(0,10), breaks = c(2, 4, 6, 8, 10))+
  ggtitle("B")
ggsave(
    filename = "tmpfigures/paper1/validationhistogram_propabun.png",
    plot = last_plot(),
    width = 14,
    height = 5,
    units = "cm",
    dpi = 300)

#bar plot of the ratio of spp presnce points to absnece points in the training data
df <- prop_abun_validation %>% 
  select(common_name, test_dat_pres, test_dat_abs) %>% 
  mutate(perc_pres = test_dat_pres/test_dat_abs) %>% 
  filter(perc_pres>0.05)
df$common_name <- str_to_title(df$common_name)
ggplot(data = df, aes(x = reorder(common_name, -perc_pres), y = perc_pres))+
  geom_bar(stat = "identity", fill = "grey", color = "black")+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
        axis.text = element_text(size = 15),
        axis.title = element_text(size = 20),
        axis.text.x = element_text(angle=45, hjust=1),
        title = element_text(size = 20))+
  labs(x = NULL, y = "Ratio")+
  coord_cartesian(ylim = c(0, .6)) +
  ggtitle("C")
ggsave(
    filename = "tmpfigures/paper1/testingdataratio.png",
    plot = last_plot(),
    width = 25,
    height = 10,
    units = "cm",
    dpi = 300)

#dot plot of the OR and the CI. The CI are so tiny bc the sample size is super big
#need to remake the results df because when we added the asterisks to the OR column for the table, it is not longer a numeric varialbe
results2 <- cond %>% 
  mutate(CIlow = estimate - (1.96*std_er),
         CIhigh = estimate + (1.96*std_er),
         OR = round(exp(estimate), 2),
         ORCIlow = round(exp(CIlow), 2),
         ORCIhigh = round(exp(CIhigh), 2)) %>% 
  arrange(common_name) %>% 
  filter(variable != "(Intercept)") 

#rename variables to make more interpretable
results2$variable[results2$variable == "annual_mean_summer_temp"] <- "mean summer temp"
results2$variable[results2$variable == "huc12_damden_sqkm"] <- "dam density"
results2$variable[results2$variable == "BFI_HIST"] <- "baseflow index"
results2$variable[results2$variable == "LO7Q1DT_HIST"] <- "low flow date"
results2$variable[results2$variable == "W95_HIST"] <- "number of winter floods"
results2$variable[results2$variable == "logMJJA_HIST"] <- "summer flow"
results2$variable[results2$variable == "lat"] <- "latitude"
results2$variable[results2$variable == "long"] <- "longitude"
results2$variable[results2$variable == "ElevCat"] <- "elevation"
results2$variable[results2$variable == "logWsAreaSqKm"] <- "watershed area"
results2$variable[results2$variable == "huc8_damcount"] <- "dam count"

#order the variables so they occurr in the correct/ same order for all figures
results2$variable <- factor(results2$variable, levels = c("mean summer temp", "baseflow index", "summer flow", "low flow date", 
                                                          "number of winter floods", 
                                                          "BFIWs", "WtDepWs", "PctImp_Ws", "pctAg_Ws", 
                                                          "pctWetland_Cat", "dam density",
                                                          "dam count", "logRdCrsCat", "PctOw_Ws", "logPctOw_Cat", 
                                                          "latitude", "longitude", "elevation", "watershed area"))

for (i in 1:length(unique(results2$common_name))) {

ggplot(data = results2[results2$common_name == unique(results2$common_name)[i],], aes(x = variable, y = OR))+
  geom_point(size = 3)+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), width = .2)+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed", size = 1)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 15),
        axis.title.y = element_blank(),
        title = element_text(size = 15))+
    ggtitle(label = unique(results2$common_name)[i])

ggsave(
    filename = paste("C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/fish_log_odd_plots/", unique(results2$common_name)[i],  ".png", sep = ""),
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )

}







# make composite OR plots to show how different temperature, tolerance, origin,  groups respond to the variables on average
# do this using the zero inflated model component

#prepare the zero inflation results file
results_zer <- zer %>% 
  mutate(CIlow = estimate - (1.96*std_er),
         CIhigh = estimate + (1.96*std_er),
         OR = round(exp(estimate), 2),
         ORCIlow = round(exp(CIlow), 2),
         ORCIhigh = round(exp(CIhigh), 2)) %>% 
  arrange(common_name) %>% 
  filter(variable != "(Intercept)") %>% 
  select(common_name, variable, OR, ORCIlow, ORCIhigh, p_val)


#fish traits
load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_datafiles/fish_traits.RData")
temperature <- read_xlsx("C:/Users/jenrogers/Documents/necascFreshwaterBio/spp_data/thermalpref_origin_tolerance.xlsx",
                  sheet = 1,
                  range = cell_cols("A:G")) %>% 
  pivot_longer(2:7, names_to = "state", values_to = "tmp") %>% 
  filter(!is.na(tmp),
         !tmp == "eury",
         !(common_name %in% c("american brook lamprey") & tmp == "cold"),
         !(common_name %in% c("common shiner", "white sucker", "smallmouth bass", "fallfish") & tmp == "warm")) %>% 
  select(-state) %>% 
  unique()

origin <- read_xlsx("C:/Users/jenrogers/Documents/necascFreshwaterBio/spp_data/thermalpref_origin_tolerance.xlsx",
                  sheet = 2,
                  range = cell_cols("A:G"))%>% 
  pivot_longer(2:7, names_to = "state", values_to = "origin") %>% 
  filter(!is.na(origin),
         !(common_name == "spottail shiner" & origin == "introduced"),
         !origin == "unk") %>% 
  select(-state) %>%  
  unique()

tolerance <- final_traits %>% 
  select(common_name, tolerance) %>% 
  unique()

#composite OR figures by cluster - can change the cluster csv to _bytemperature, _bystreamflow, or just fish clusters
clusters <- read.csv("tmpfigures/fishclusters_bytemperature.csv")
clusters <- clusters %>% 
  select(-1) %>% 
  rename(cluster_TP = final.cluster)

clusters2 <- read.csv("tmpfigures/fishclusters_bystreamflow.csv")
clusters2 <- clusters2 %>% 
  select(-1) %>% 
  rename(cluster_SF = final.cluster)

composit_OR_figs <- left_join(results_zer, clusters, by = "common_name") %>% 
  left_join(temperature, by  = "common_name") %>% 
  left_join(clusters2, by  = "common_name") %>% 
  left_join(origin, by = "common_name") %>% 
  left_join(tolerance, by = "common_name") %>% 
  filter(! OR > 20,
         ! ORCIhigh > 20)

#rename variables to make more interpret able
composit_OR_figs$variable[composit_OR_figs$variable == "annual_mean_summer_temp"] <- "mean summer T"
composit_OR_figs$variable[composit_OR_figs$variable == "huc12_damden_sqkm"] <- "dam density"
composit_OR_figs$variable[composit_OR_figs$variable == "BFI_HIST"] <- "baseflow index"
composit_OR_figs$variable[composit_OR_figs$variable == "LO7Q1DT_HIST"] <- "low flow date"
composit_OR_figs$variable[composit_OR_figs$variable == "W95_HIST"] <- "winter floods"
composit_OR_figs$variable[composit_OR_figs$variable == "logMJJA_HIST"] <- "summer flow"
composit_OR_figs$variable[composit_OR_figs$variable == "lat"] <- "latitude"
composit_OR_figs$variable[composit_OR_figs$variable == "long"] <- "longitude"
composit_OR_figs$variable[composit_OR_figs$variable == "ElevCat"] <- "elevation"
composit_OR_figs$variable[composit_OR_figs$variable == "logWsAreaSqKm"] <- "watershed area"
composit_OR_figs$variable[composit_OR_figs$variable == "huc8_damcount"] <- "dam count"
composit_OR_figs$variable[composit_OR_figs$variable == "pctWetland_Cat"] <- "wetland"
composit_OR_figs$variable[composit_OR_figs$variable == "pctAg_Ws"] <- "agriculture"
composit_OR_figs$variable[composit_OR_figs$variable == "PctImp_Ws"] <- "impervious"
composit_OR_figs$variable[composit_OR_figs$variable == "WtDepWs"] <- "water table dep"
composit_OR_figs$variable[composit_OR_figs$variable == "logPctOw_Cat"] <- "open water"

#order the variables so they occurr in the correct/ same order for all figures
composit_OR_figs$variable <- factor(composit_OR_figs$variable, levels = c("mean summer T", "baseflow index", "summer flow", "low flow date", "winter floods", 
                                                          "BFIWs", "water table dep", "impervious", "agriculture", 
                                                          "wetland", "dam density",
                                                          "dam count", "logRdCrsCat", "PctOw_Ws", "open water", 
                                                          "latitude", "longitude", "elevation", "watershed area"))

composit_OR_figs <- composit_OR_figs %>% 
  filter(variable %in% c("mean summer T", "baseflow index", "summer flow", "low flow date", "winter floods", 
                                                          "water table dep", "impervious", "agriculture", 
                                                          "wetland", "dam density","open water", 
                                                          "latitude", "elevation", "watershed area"))

composit_OR_fig_tmpclust <- composit_OR_figs%>% 
  filter(!is.na(cluster_TP),
         common_name !="brook trout") %>%
  group_by(cluster_TP, variable) %>% 
  summarise(OR = median(OR, na.rm = T),
            ORCIlow = median(ORCIlow, na.rm = T),
            ORCIhigh = median(ORCIhigh, na.rm = T)) %>% 
  filter(ORCIlow  > 1 & ORCIhigh > 1 | ORCIlow  < 1 & ORCIhigh < 1)
composit_OR_fig_tmpclust$cluster_TP[composit_OR_fig_tmpclust$cluster_TP == 1] <- "1-cold, mid elevation"
composit_OR_fig_tmpclust$cluster_TP[composit_OR_fig_tmpclust$cluster_TP == 2] <- "2-warm, sm watersheds"
composit_OR_fig_tmpclust$cluster_TP[composit_OR_fig_tmpclust$cluster_TP == 3] <- "3-cool, low elevation"
composit_OR_fig_tmpclust$cluster_TP[composit_OR_fig_tmpclust$cluster_TP == 4] <- "4-cool, mid elevation"
composit_OR_fig_tmpclust$cluster_TP[composit_OR_fig_tmpclust$cluster_TP == 5] <- "5-cold, high elevation"
composit_OR_fig_tmpclust$cluster_TP[composit_OR_fig_tmpclust$cluster_TP == 6] <- "6-warm, lg watersheds"

composit_OR_fig_flowclust <- composit_OR_figs%>% 
  filter(!is.na(cluster_SF),
         common_name !="brook trout") %>%
  group_by(cluster_SF, variable) %>% 
  summarise(OR = median(OR, na.rm = T),
            ORCIlow = median(ORCIlow, na.rm = T),
            ORCIhigh = median(ORCIhigh, na.rm = T)) %>% 
  filter(ORCIlow  > 1 & ORCIhigh > 1 | ORCIlow  < 1 & ORCIhigh < 1)
composit_OR_fig_flowclust$cluster_SF[composit_OR_fig_flowclust$cluster_SF == 1] <- "1-Many floods, med Su Q"
composit_OR_fig_flowclust$cluster_SF[composit_OR_fig_flowclust$cluster_SF == 2] <- "2-Mod floods, low Su Q"
composit_OR_fig_flowclust$cluster_SF[composit_OR_fig_flowclust$cluster_SF == 3] <- "3-Many floods, low Su Q"
composit_OR_fig_flowclust$cluster_SF[composit_OR_fig_flowclust$cluster_SF == 4] <- "4-mod floods, med Su Q"
composit_OR_fig_flowclust$cluster_SF[composit_OR_fig_flowclust$cluster_SF == 5] <- "5-Many floods, high Su Q"
composit_OR_fig_flowclust$cluster_SF[composit_OR_fig_flowclust$cluster_SF == 6] <- "6-Few floods, med Su Q"


composit_OR_fig_tempGrops <- composit_OR_figs%>% 
  filter(!is.na(tmp),
         common_name !="brook trout") %>%
  group_by(tmp, variable) %>% 
  summarise(OR = median(OR, na.rm = T),
            ORCIlow = median(ORCIlow, na.rm = T),
            ORCIhigh = median(ORCIhigh, na.rm = T)) %>% 
  filter(ORCIlow  > 1 & ORCIhigh > 1 | ORCIlow  < 1 & ORCIhigh < 1)

composit_OR_fig_tol <- composit_OR_figs%>% 
  filter(!is.na(tolerance),
         common_name !="brook trout") %>%
  group_by(tolerance, variable) %>% 
  summarise(OR = median(OR, na.rm = T),
            ORCIlow = median(ORCIlow, na.rm = T),
            ORCIhigh = median(ORCIhigh, na.rm = T)) %>% 
  filter(ORCIlow  > 1 & ORCIhigh > 1 | ORCIlow  < 1 & ORCIhigh < 1)

composit_OR_fig_origin <- composit_OR_figs%>% 
  filter(!is.na(origin)) %>%
  group_by(origin, variable) %>% 
  summarise(OR = median(OR, na.rm = T),
            ORCIlow = median(ORCIlow, na.rm = T),
            ORCIhigh = median(ORCIhigh, na.rm = T)) %>% 
  filter(ORCIlow  > 1 & ORCIhigh > 1 | ORCIlow  < 1 & ORCIhigh < 1)

composit_OR_fig_BT <- composit_OR_figs%>% 
  filter(common_name == "brook trout",
         !is.na(common_name)) %>% 
  filter(ORCIlow  > 1 & ORCIhigh > 1 | ORCIlow  < 1 & ORCIhigh < 1)


a <- ggplot(data = composit_OR_fig_tmpclust, aes(x = variable, y = OR))+
  geom_point(size = 1.5, position=position_dodge(width=0.5))+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), position=position_dodge(width=0.5))+
  coord_flip()+
  facet_wrap(~as.factor(cluster_TP), nrow = 2)+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed", size = 1)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.background = element_blank(),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 15),
        axis.title.y = element_blank(),
        title = element_text(size = 15))+
  labs(y = "odds ratio", title = "Temperature Clusters")

b <- ggplot(data = composit_OR_fig_flowclust, aes(x = variable, y = OR))+
  geom_point(size = 1.5, position=position_dodge(width=0.5))+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), position=position_dodge(width=0.5))+
  coord_flip()+
  facet_wrap(~as.factor(cluster_SF), nrow = 2)+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed", size = 1)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.background = element_blank(),
        axis.title = element_text(size = 15),
        axis.title.y = element_blank(),
        title = element_text(size = 15))+
  labs(y = NULL, title = "Streamflow Clusters")

c <- ggplot(data = composit_OR_fig_tempGrops, aes(x = variable, y = OR))+
  geom_point(size = 1.5, position=position_dodge(width=0.5))+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), position=position_dodge(width=0.5))+
  coord_flip()+
  facet_wrap(~as.factor(tmp), nrow = 6)+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed", size = 1)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.background = element_blank(),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 15),
        axis.title.y = element_blank(),
        title = element_text(size = 15))+
  labs(y = NULL, title = "Temp Guilds")
d <- ggplot(data = composit_OR_fig_tol, aes(x = variable, y = OR))+
  geom_point(size = 1.5, position=position_dodge(width=0.5))+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), position=position_dodge(width=0.5))+
  coord_flip()+
  facet_wrap(~as.factor(tolerance), nrow = 6)+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed", size = 1)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.background = element_blank(),
        axis.title = element_text(size = 15),
        axis.title.y = element_blank(),
        title = element_text(size = 15))+
  labs(y = NULL, title = "Habitat Guilds")

e <- ggplot(data = composit_OR_fig_BT, aes(x = variable, y = OR))+
  geom_point(size = 1.5, position=position_dodge(width=0.5))+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), position=position_dodge(width=0.5))+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed", size = 1)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.background = element_blank(),
        axis.title = element_text(size = 15),
        axis.title.y = element_blank(),
        title = element_text(size = 15))+
  labs(y = NULL, title = "Brook Trout")

ggsave(e, file = "tmpfigures/paper1/CompositORPlotsBT.png", 
    width = 15,
    height = 10,
    units = "cm",
    dpi = 300)

library(cowplot)
g <- plot_grid(a,c, align = "h", nrow = 1, rel_widths = c(2/3, 1/3))
ggsave(g, file = "tmpfigures/paper1/CompositORPlots3.png", 
    width = 25,
    height = 15,
    units = "cm",
    dpi = 300)

g <- plot_grid(b,d, align = "h", nrow = 1, rel_widths = c(2/3, 1/3))
ggsave(g, file = "tmpfigures/paper1/CompositORPlots4.png", 
    width = 25,
    height = 15,
    units = "cm",
    dpi = 300)



#try showing the plots differentlyfor the temperature guilds/clusters so we can clearly see how the guilds compare to the cluster counterparsk
#facet by cold cool and warm and brook trout, color by the cluster/guild

names(composit_OR_fig_BT)
names(composit_OR_fig_tempGrops)
names(composit_OR_fig_tmpclust)

composit_OR_fig_tempGrops$group <- "guild"
names(composit_OR_fig_tmpclust)[1] <- "group"
composit_OR_fig_tmpclust$tmp <- ifelse(composit_OR_fig_tmpclust$group %in% c("1-cold, mid elevation", "5-cold, high elevation"), "cold",
                                       if_else(composit_OR_fig_tmpclust$group %in% c("2-warm, sm watersheds", "6-warm, lg watersheds"), "warm", "cool"))
composit_OR_fig_BT <- composit_OR_fig_BT %>% 
  rename(group = common_name) %>% 
  select(group, tmp, variable, OR, ORCIlow, ORCIhigh)

tempgrps <- rbind(composit_OR_fig_tempGrops, composit_OR_fig_tmpclust, composit_OR_fig_BT)

a <- ggplot(data = tempgrps[tempgrps$tmp == "cold",], aes(x = variable, y = OR, color = group))+
  geom_point(size = 1.5, position=position_dodge(width=0.5))+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), position=position_dodge(width=0.5))+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed", size = 1)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.background = element_blank(),
        axis.text = element_text(size = 12),
        axis.title.y = element_blank(),
        title = element_text(size = 15))+
  labs(y = NULL, title = "Cold")
b <- ggplot(data = tempgrps[tempgrps$tmp == "cool",], aes(x = variable, y = OR, color = group))+
  geom_point(size = 1.5, position=position_dodge(width=0.5))+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), position=position_dodge(width=0.5))+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed", size = 1)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.background = element_blank(),
        axis.text = element_text(size = 12),
        axis.title.y = element_blank(),
        title = element_text(size = 15))+
  labs(y = NULL, title = "Cool")
c <- ggplot(data = tempgrps[tempgrps$tmp == "warm",], aes(x = variable, y = OR, color = group))+
  geom_point(size = 1.5, position=position_dodge(width=0.5))+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), position=position_dodge(width=0.5))+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed", size = 1)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.background = element_blank(),
        axis.text = element_text(size = 12),
        axis.title.y = element_blank(),
        title = element_text(size = 15))+
  labs(y = NULL, title = "Warm")

g <- plot_grid(a,b,c, align = "v", nrow = 3, rel_widths = c(1/3, 1/3, 1/3))
ggsave(g, file = "tmpfigures/paper1/CompositORPlot_TemperatureGrp.png", 
    width = 20,
    height = 25,
    units = "cm",
    dpi = 300)







#make a tile plot to show the coef value for each variable by fish

#set outliers to more similar values so the color scale works
results3 <- results_zer
results3$OR[results3$OR>10] <- 10
results3$OR[results3$OR < 0.00001] <- 0.00001
results3$estimate[results3$p_val > 0.05] <- NA
results3$OR[results3$p_val > 0.05] <- NA

ggplot(results3, aes(x = variable, y = common_name, fill = OR))+
  geom_tile()+
  theme(axis.text.x = element_text(angle = 45, hjust=1, size = 18))+
  scale_fill_gradient2(low = "red",
                       mid = "white",
                       high = "blue",
                       midpoint = 0)+
  labs(x = NULL, y = NULL)

ggsave(
    filename = "tmpfigures/prop_abun_tileplot.png",
    plot = last_plot(),
    width = 18,
    height = 18,
    units = "cm",
    dpi = 200
  )

#counts the number of significant variables (ie how many species is each variable significant for?)
 results4 <- results_zer %>% 
   select(variable, estimate) %>% 
   filter(!is.na(estimate)) %>% 
   group_by(variable) %>% 
   summarize(count = n()) %>% 
   arrange(desc(count))
 write.csv(results4, "tmpfigures/propabund_sigvaraibles.csv")


# 
# #cluster spp based on their coef values
# 
# library(factoextra)
# 
# cluster <- results2 %>% 
#   select(variable, common_name, OR) %>% 
#   pivot_wider(names_from = variable, values_from = OR) %>% 
#   data.frame()
# cluster2 <- cluster[,-1]
# rownames(cluster2) <- cluster[,1]
# 
# cluster2 <- scale(cluster2)
# 
# distance <- get_dist(cluster2)
#  
# fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
# 
# 
# k2 <- kmeans(distance, centers = 7, nstart = 25)
# str(k2)
# k2
# fviz_cluster(k2, data = distance)
#   
# 
# 
# #NMDS
# library(vegan)
# library(tidyverse)
# 
# #fish data
# load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_datafiles/fish_count_with_zeros.RData")
# 
# #tidied covariates (this is called fishcovariates)
# load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_datafiles/model_covariates.RData")
# 
# 
# 
# 
# counts <- fish_count_with_zeros %>%
#   filter(gear == "efish_backpack",
#          run_num ==1,
#          stock == "natural") %>% 
#   group_by(UID) %>% 
#   mutate(totalcount = sum(count)) %>% 
#   ungroup() %>% 
#   filter(totalcount>0) %>% 
#   mutate(propabun = (count / totalcount))
# 
# 
# #join the counts to the tidying covariates, fishcovariates
# 
# #There are some duplicated UIDs so we want to remove them
# test <- left_join(counts, fishcovariates, by = "UID") %>% 
#   mutate(occurrence = ifelse(count>0, 1, 0)) %>% 
#   select(1, 4,  15,16, 17, 23:52) %>% 
#   group_by(UID, lat, long, annual_mean_summer_temp, BFI_HIST, LO7Q1DT_HIST, CFM_HIST, W95_HIST, BFIWs, ElevCat, RdDensCatRp100, RdDensWsRp100, RdCrsWs, WtDepWs, PopDen_Ws, PctOw_Ws, PctImp_Cat, PctImp_Ws, PctImp_CatRp100, PctImp_WsRp100, pctForest_Cat, pctForest_ws, pctUrban_Cat, pctUrban_ws, pctAg_Ws, pctWetland_Cat, pctWetland_Ws, huc12_damden_sqkm, huc8_damcount, logWsAreaSqKm, logMJJA_HIST, logRdCrsCat, logPctOw_Cat, common_name) %>%
#   summarise(n = n()) %>%
#   filter(n > 1)
# unique(test$UID)
# #[1] "RI_3_1_16_1170509"  "RI_4_1_4_1170810"   "RI_9_NA_60_1100709"
# 
# counts <- counts %>% 
#   filter(!UID == "RI_3_1_16_1170509" & !UID == "RI_4_1_4_1170810" & !UID == "RI_9_NA_60_1100709")
# 
# test <- left_join(counts, fishcovariates, by = "UID") %>% 
#   mutate(occurrence = ifelse(count>0, 1, 0)) %>% 
#   select(1, 4,  15,16, 17, annual_mean_summer_temp, 
#                  BFI_HIST, 
#                  LO7Q1DT_HIST,
#                  W95_HIST, 
#                  BFIWs,  
#                  WtDepWs, 
#                  PctOw_Ws,  
#                  PctImp_Ws,  
#                  pctAg_Ws, 
#                  pctWetland_Cat, 
#                  logMJJA_HIST, 
#                  logRdCrsCat, 
#                  logPctOw_Cat,
#                  huc12_damden_sqkm,
#                  huc8_damcount) %>%  
#   filter(common_name %in% c("american eel", "white perch", "finescale dace", "american brook lamprey", 
#                             "cutlips minnow", "green sunfish", "central mudminnow", "bridle shiner", 
#                             "swamp darter", "lake chub", "banded killifish", "margined madtom", "burbot", "black crappie", 
#                             "spottail shiner", "redbelly dace", "creek chubsucker", "banded sunfish", "fathead minnow", 
#                             "bluntnose minnow", "redbreast sunfish", "rock bass", "rainbow trout", "longnose sucker", 
#                             "smallmouth bass", "yellow bullhead", "redfin pickerel", "yellow perch", "brown bullhead", 
#                             "atlantic salmon", "golden shiner", "chain pickerel", "bluegill", "brown trout", "tessellated darter", 
#                             "largemouth bass", "fallfish", "common shiner", "creek chub", "pumpkinseed", "slimy sculpin", 
#                             "longnose dace", "white sucker", "eastern blacknose dace", "brook trout")) %>% 
#   pivot_wider(names_from = "common_name", values_from = "propabun")
# 
# sapply(test, function(x) sum(is.na(x)))
# 
# test <- test[complete.cases(test),]
# 
# #com <-  test[,25:102] #Takes a really long time.. maybe do a few at a time
# com <-  test[,19:62]
# env <-  test[,2:18]
# 
# #count NAs in each spreadsheed
# sapply(com, function(x) sum(is.na(x)))
# sapply(env, function(x) sum(is.na(x)))
# 
# 
# 
# 
# m_com <-  as.matrix(com)
# 
# #nmds code
# set.seed(4352)
# nmds <-   metaMDS(m_com, distance = "gower")
# nmds
# save(nmds, file = "C:/Users/jenrogers/Documents/necascFreshwaterBio/model_objects/fishNMDS.rda")
# 
# en <- envfit(nmds, env, permutations = 999, na.rm = TRUE)
# plot(nmds, type='t', display=c('species'))
# 
# 
# 
# png(height = 15, width = 15, file = "tmpfigures/nmds.png", units = "in", res = 150, type = "cairo")
# 
# 
# plot(nmds, type='t', display=c('species'), cex = 1.5)
# plot(en)
# 
# dev.off()

```



Logistic Regression Model of presence and absence at the stream reach scale




```{r}
#models at the stream reach scale
library(glmmTMB)

#filter the fish names to be only those that we agreed as a group we would include
fish_occurrence_filtererd <- fish_occurrence %>% 
  filter(common_name %in% c("american eel", "white perch", "rosyside dace", "channel catfish", "bowfin", "round whitefish", 
                            "white catfish", "spotfin shiner", "mimic shiner", "finescale dace", "american brook lamprey", 
                            "eastern silvery minnow", "rosyface shiner", "walleye", "cutlips minnow", "green sunfish", 
                            "brook stickleback", "common carp", "central mudminnow", "northern pike", "bridle shiner", 
                            "swamp darter", "lake chub", "banded killifish", "margined madtom", "burbot", "black crappie", 
                            "spottail shiner", "redbelly dace", "creek chubsucker", "banded sunfish", "fathead minnow", 
                            "bluntnose minnow", "redbreast sunfish", "rock bass", "rainbow trout", "longnose sucker", 
                            "smallmouth bass", "yellow bullhead", "redfin pickerel", "yellow perch", "brown bullhead", 
                            "atlantic salmon", "golden shiner", "chain pickerel", "bluegill", "brown trout", "tessellated darter", 
                            "largemouth bass", "fallfish", "common shiner", "creek chub", "pumpkinseed", "slimy sculpin", 
                            "longnose dace", "white sucker", "eastern blacknose dace", "brook trout")) %>% 
  select(-stock)

occurrence <- fish_occurrence_filtererd %>%
  filter(common_name == "white sucker")

hist(occurrence$occurrence)

#plot the observed proportional abundance
shp <- left_join(fish_shp, occurrence, by = "UID") %>%
  filter(!is.na(occurrence))
ggplot(data = shp[shp$occurrence ==1,])+
  geom_sf(aes(color = occurrence))

load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_datafiles/model_covariates.RData")

fishcovariates <- fishcovariates[complete.cases(fishcovariates),]
test <- fishcovariates[,c(2:3, 9:38)]
test <- data.frame(scale(test))

fishcovariates <- cbind((fishcovariates)[,c(1, 4:8)], test)


#join the occurrence to the tidying covariates, fishcovariates
dat <- left_join(occurrence, fishcovariates, by = "UID")


dat <- dat %>%  
  select(UID, common_name, occurrence, state, huc8_name, 11:42)


#plot of variables vs occurrence
dat$occurrence <- as.factor(dat$occurrence)
ggplot(data = dat, mapping = aes(x = occurrence, y = pctForest_ws))+
  geom_violin()+
  geom_boxplot(width = 0.1)+
  geom_smooth(method = "lm")+
    theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank())+
  labs(title = "white sucker")



#two options to further reduce the variable list:

# PCA to combine all the variables used in the conditional model (or both models?) need to do this

#simple binomial models to identify which variables are not related to the outcome
# mdl <- glmmTMB(propabun ~ huc8_damcount,
#                data = dat,
#                family = "binomial")
# summary(mdl)


dat <- dat %>% 
  filter(!is.na(lat))

#set aside 20% for validation and put 80% into the calibration dataset
n_obs <- nrow(dat)
permuted_rows <- sample(n_obs)
dat <- dat[permuted_rows,]
split <- round(n_obs * 0.8)
set.seed(3223)
train <- dat[1:split, ]
test <- dat[(split+1):n_obs, ]

#global model
mdl <- glm(occurrence ~
                 annual_mean_summer_temp + 
                 BFI_HIST + 
                 LO7Q1DT_HIST +
                 W95_HIST + 
                 BFIWs +   
                 WtDepWs + 
                 PctOw_Ws +  
                 PctImp_Ws +  
                 pctAg_Ws + 
                 pctWetland_Cat +
                 logPctOw_Cat + 
                 logMJJA_HIST + 
                 logRdCrsCat +
                 huc12_damden_sqkm +
                 huc8_damcount +
                 lat +
                 long +
                 ElevCat + 
                 logWsAreaSqKm,
               data = train,
               family = binomial)

summary(mdl)
saveRDS(mdl, paste("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_objects/pres_", unique(dat$common_name), ".rds", sep = ""))

#make a table of the model resuls


results <- 
  data.frame(
    "estimate" = summary(mdl)$coefficients[,1],
    "std_er" = summary(mdl)$coefficients[,2],
    "p_val" = summary(mdl)$coefficients[,4],
    "variable" = rownames(summary(mdl)$coefficients))

results$common_name <- unique(dat$common_name)

#use model to predict on testing data
predict_resp <- predict(mdl, test, type = 'response') #the predicted value


#compare the predicted zeros to the actual zeros
compare <- data.frame(
  "common_name" = test$common_name,
  "occurrence" = factor(test$occurrence),
  "pred_occurrence" = factor(ifelse(predict_resp > 0.3, 1, 0), levels = levels(factor(test$occurrence)))
)
compare <- na.omit(compare)

#validations for the predicted occurrence vs the actual occurrence
compare$pred_occurrence <- factor(compare$pred_occurrence, levels = c(1,0))
compare$occurrence <- factor(compare$occurrence, levels = c(1,0))
cm <- confusionMatrix(reference = compare$occurrence, data = compare$pred_occurrence)

val_zero_prob <- data.frame(
  "common_name" = unique(train$common_name),
  "test_dat_pres" = nrow(test[test$occurrence == 1,]),
  "test_dat_abs" = nrow(test[test$occurrence == 0,]),
  "train_dat_pres" = nrow(train[train$occurrence == 1, ]),
  "train_dat_abs" = nrow(train[train$occurrence == 0, ]),
  "accuracy" = cm$overall[1],
  "sensitivity" = cm$byClass[1],
  "Specificity" = cm$byClass[2],
  "Pos Pred Value" = cm$byClass[3],
  "Neg Pred Value" = cm$byClass[4]
)


#Start the for loop here

for (i in 2:length(unique(fish_occurrence_filtererd$common_name))) { #start with 2 bc we used white sucker as the started spp above
  


occurrence <- fish_occurrence_filtererd %>%
  filter(common_name == unique(fish_occurrence_filtererd$common_name)[i])


#join the occurrence to the tidying covariates, fishcovariates
dat <- left_join(occurrence, fishcovariates, by = "UID")
dat <- dat[complete.cases(dat),]#ahhhh

dat <- dat %>% 
  filter(!is.na(lat))

#set aside 20% for validation and put 80% into the calibration dataset
n_obs <- nrow(dat)
permuted_rows <- sample(n_obs)
dat <- dat[permuted_rows,]
split <- round(n_obs * 0.8)
set.seed(32435)
train <- dat[1:split, ]
test <- dat[(split+1):n_obs, ]


#global model
mdl <- glm(occurrence ~
                 annual_mean_summer_temp + 
                 BFI_HIST + 
                 LO7Q1DT_HIST +
                 W95_HIST + 
                 BFIWs +   
                 WtDepWs + 
                 PctOw_Ws +  
                 PctImp_Ws +  
                 pctAg_Ws  +
                 logPctOw_Cat +  
                 pctWetland_Cat + 
                 logMJJA_HIST + 
                 logRdCrsCat  +
                 huc12_damden_sqkm +
                 huc8_damcount +
                 lat +
                 long +
                 ElevCat + 
                 logWsAreaSqKm,
               data = train,
               family = binomial)

saveRDS(mdl, paste("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_objects/pres_", unique(fish_occurrence_filtererd$common_name)[i], ".rds", sep = ""))

#make a table of the model resuls


tmp <- 
  data.frame(
    "estimate" = summary(mdl)$coefficients[,1],
    "std_er" = summary(mdl)$coefficients[,2],
    "p_val" = summary(mdl)$coefficients[,4],
    "variable" = rownames(summary(mdl)$coefficients))

tmp$common_name <- unique(fish_occurrence_filtererd$common_name)[i]



results <- rbind(results, tmp)

#use model to predict on testing data
predict_resp <- predict(mdl, test, type = 'response') #the predicted value

compare <- data.frame(
  "common_name" = rep(unique(train$common_name), nrow(test)),
  "occurrence" = factor(test$occurrence),
  "pred_occurrence" = factor(ifelse(predict_resp > 0.3, 1, 0), levels = levels(factor(test$occurrence)))
)

compare$pred_occurrence <- factor(compare$pred_occurrence, levels = c(1,0))
compare$occurrence <- factor(compare$occurrence, levels = c(1,0))

cm <- confusionMatrix(reference = compare$occurrence, data = compare$pred_occurrence)

val2 <- data.frame(
  "common_name" = unique(train$common_name),
  "test_dat_pres" = nrow(test[test$occurrence == 1,]),
  "test_dat_abs" = nrow(test[test$occurrence == 0,]),
  "train_dat_pres" = nrow(train[train$occurrence == 1, ]),
  "train_dat_abs" = nrow(train[train$occurrence == 0, ]),
  "accuracy" = cm$overall[1],
  "sensitivity" = cm$byClass[1],
  "Specificity" = cm$byClass[2],
  "Pos Pred Value" = cm$byClass[3],
  "Neg Pred Value" = cm$byClass[4]
)
val_zero_prob <- rbind(val_zero_prob, val2)


print(unique(fish_occurrence_filtererd$common_name)[i])

}

write.csv(val_zero_prob, file = "tmpfigures/val_zero_prob_logistic_reg_mdl.csv")

#filter to remove spp that did not converge, these include:
#rosyside dace,  round whitefish, rosyface shiner, spotfin shiner

results <- results %>% 
  filter(common_name %in% c("bowfin", "white catfish", "mimic shiner", "walleye", "rosyface shiner", "spotfin shiner",
                            "american eel", "common carp", "northern pike", "channel catfish", "eastern silvery minnow", 
                            "white perch", "finescale dace", "american brook lamprey", "brook stickleback",
                            "green sunfish", "central mudminnow", "bridle shiner", "cutlips minnow",
                            "swamp darter", "lake chub", "banded killifish", "margined madtom", "burbot", "black crappie", 
                            "spottail shiner", "redbelly dace", "creek chubsucker", "banded sunfish", "fathead minnow", 
                            "bluntnose minnow", "redbreast sunfish", "rock bass", "rainbow trout", "longnose sucker", 
                            "smallmouth bass", "yellow bullhead", "redfin pickerel", "yellow perch", "brown bullhead", 
                            "atlantic salmon", "golden shiner", "chain pickerel", "bluegill", "brown trout", "tessellated darter", 
                            "largemouth bass", "fallfish", "common shiner", "creek chub", "pumpkinseed", "slimy sculpin", 
                            "longnose dace", "white sucker", "eastern blacknose dace", "brook trout"))


#calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results2 <- results %>% 
  mutate(CIlow = estimate - (1.96*std_er),
         CIhigh = estimate + (1.96*std_er),
         OR = exp(estimate),
         ORCIlow = exp(CIlow),
         ORCIhigh = exp(CIhigh)) %>% 
  arrange(OR) %>% 
  filter(variable != "(Intercept)")

pres_abs_fish_mdl_results <- results2
save(pres_abs_fish_mdl_results, file = "C:/Users/jenrogers/Documents/necascFreshwaterBio/model_results/pres_abs_fish_mdl_results.RData")
load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_results/pres_abs_fish_mdl_results.RData")

#rename variables to make more interpretable
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "annual_mean_summer_temp"] <- "mean summer temp"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "huc12_damden_sqkm"] <- "dam density"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "BFI_HIST"] <- "baseflow index"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "LO7Q1DT_HIST"] <- "low flow date"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "W95_HIST"] <- "number of winter floods"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "logMJJA_HIST"] <- "summer flow"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "lat"] <- "latitude"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "long"] <- "longitude"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "ElevCat"] <- "elevation"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "logWsAreaSqKm"] <- "watershed area"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "huc8_damcount"] <- "dam count"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "pctWetland_Cat"] <- "wetland"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "pctAg_Ws"] <- "agriculture"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "PctImp_Ws"] <- "impervious"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "WtDepWs"] <- "water table depth"
pres_abs_fish_mdl_results$variable[pres_abs_fish_mdl_results$variable == "logPctOw_Cat"] <- "open water"

#order the variables so they occurr in the correct/ same order for all figures
pres_abs_fish_mdl_results$variable <- factor(pres_abs_fish_mdl_results$variable, levels = c("mean summer temp", "baseflow index", "summer flow", "low flow date", 
                                                          "number of winter floods", 
                                                          "BFIWs", "water table depth", "impervious", "agriculture", 
                                                          "wetland", "dam density",
                                                          "dam count", "logRdCrsCat", "PctOw_Ws", "open water", 
                                                          "latitude", "longitude", "elevation", "watershed area"))


#dot plot of the OR and the CI. The CI are so tiny bc the sample size is super big

for (i in 1:length(unique(pres_abs_fish_mdl_results$common_name))) {

ggplot(data = pres_abs_fish_mdl_results[pres_abs_fish_mdl_results$common_name == unique(pres_abs_fish_mdl_results$common_name)[i],], aes(x = variable, y = OR))+
  geom_point(size = 3)+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), linewidth = .2)+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed", size = 1)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 15),
        axis.title.y = element_blank(),
        title = element_text(size = 15))+
    ggtitle(label = unique(pres_abs_fish_mdl_results$common_name)[i])

ggsave(
    filename = paste("C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/fish_log_odd_plots/pres_", unique(pres_abs_fish_mdl_results$common_name)[i],  ".png", sep = ""),
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )

}



#make composite OR plots to show how different temperature or origin groups respond to the variables on average
#fish traits
load("C:/Users/jenrogers/Documents/necascFreshwaterBio/model_datafiles/fish_traits.RData")
temperature <- read_xlsx("C:/Users/jenrogers/Documents/necascFreshwaterBio/spp_data/thermalpref_origin_tolerance.xlsx",
                  sheet = 1,
                  range = cell_cols("A:G")) %>% 
  pivot_longer(2:7, names_to = "state", values_to = "tmp") %>% 
  filter(!is.na(tmp),
         !tmp == "eury",
         !(common_name %in% c("american brook lamprey") & tmp == "cold"),
         !(common_name %in% c("common shiner", "white sucker", "smallmouth bass", "fallfish") & tmp == "warm")) %>% 
  select(-state) %>% 
  unique()

origin <- read_xlsx("C:/Users/jenrogers/Documents/necascFreshwaterBio/spp_data/thermalpref_origin_tolerance.xlsx",
                  sheet = 2,
                  range = cell_cols("A:G"))%>% 
  pivot_longer(2:7, names_to = "state", values_to = "origin") %>% 
  filter(!is.na(origin),
         !(common_name == "spottail shiner" & origin == "introduced"),
         !origin == "unk") %>% 
  select(-state) %>%  
  unique()

#compoisit OR figures by cluster - can change the cluster csv to _byclimate, _bygeography, or just fish clusters
clusters <- read.csv("tmpfigures/fishclusters_byclimate.csv")
clusters <- clusters %>% 
  select(-1) %>% 
  rename(cluster = final.cluster)

composit_OR_figs <- left_join(pres_abs_fish_mdl_results, clusters, by = "common_name") %>% 
  left_join(temperature, by  = "common_name") %>% 
  filter(! OR > 20,
         ! ORCIhigh > 20,
         !is.na(cluster),
         !variable %in% c("latitude", "longitude", "elevation", "watershed area", "BFIWs", "PctOw_Ws", "logRdCrsCat")) %>%
  group_by(cluster, variable) %>% 
  summarise(OR = median(OR, na.rm = T),
            ORCIlow = median(ORCIlow, na.rm = T),
            ORCIhigh = median(ORCIhigh, na.rm = T))

ggplot(data = composit_OR_figs, aes(x = variable, y = OR, color = as.factor(cluster)))+
  geom_point(size = 1.5, position=position_dodge(width=0.5))+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), position=position_dodge(width=0.5))+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed", size = 1)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 15),
        axis.title.y = element_blank(),
        title = element_text(size = 15))+
  labs(color = "cluster")

ggsave(
    filename = paste("tmpfigures/paper1/ORcomposit_pres_abs_byclimate.png", sep = ""),
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )

#compostit OR plots by temperature guild
composit_OR_figs <- left_join(pres_abs_fish_mdl_results, temperature, by = "common_name") %>% 
  filter(! OR > 20,
         ! ORCIhigh > 20,
         !is.na(tmp),
         !variable %in% c("latitude", "longitude", "elevation", "watershed area", "BFIWs", "PctOw_Ws", "logRdCrsCat")) %>%
  group_by(tmp, variable) %>% 
  summarise(OR = median(OR, na.rm = T),
            ORCIlow = median(ORCIlow, na.rm = T),
            ORCIhigh = median(ORCIhigh, na.rm = T))

ggplot(data = composit_OR_figs, aes(x = variable, y = OR, color = as.factor(tmp)))+
  geom_point(size = 1.5, position=position_dodge(width=0.5))+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), position=position_dodge(width=0.5))+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed", size = 1)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 15),
        axis.title.y = element_blank(),
        title = element_text(size = 15))+
  labs(color = "Temp")

ggsave(
    filename = paste("tmpfigures/paper1/ORcomposit_pres_abs_bytemp.png", sep = ""),
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )

#compostit OR plots by flucial dependence guild
composit_OR_figs <- left_join(pres_abs_fish_mdl_results, final_traits, by = "common_name") %>% 
  filter(! OR > 20,
         ! ORCIhigh > 20,
         !is.na(tolerance),
         !variable %in% c("latitude", "longitude", "elevation", "watershed area", "BFIWs", "PctOw_Ws", "logRdCrsCat")) %>%
  group_by(tolerance, variable) %>% 
  summarise(OR = median(OR, na.rm = T),
            ORCIlow = median(ORCIlow, na.rm = T),
            ORCIhigh = median(ORCIhigh, na.rm = T))

ggplot(data = composit_OR_figs, aes(x = variable, y = OR, color = as.factor(tolerance)))+
  geom_point(size = 1.5, position=position_dodge(width=0.5))+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), position=position_dodge(width=0.5))+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed", size = 1)+
  theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 15),
        axis.title.y = element_blank(),
        title = element_text(size = 15))+
  labs(color = "tolerance")

ggsave(
    filename = paste("tmpfigures/paper1/ORcomposit_pres_abs_bytolerance.png", sep = ""),
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )



#make a tile plot to show the coef value for each variable by fish

#set outliers to more similar values so the color scale works
load(file = "C:/Users/jenrogers/Documents/necascFreshwaterBio/model_results/pres_abs_fish_mdl_results.RData")

results3 <- pres_abs_fish_mdl_results
results3$OR[results3$OR>10] <- 10
results3$OR[results3$OR < 0.00001] <- 0.00001
results3$estimate[results3$estimate < -5] <- -5
results3$estimate[results3$estimate > 5] <- 5
results3$estimate[results3$p_val > 0.05] <- NA

ggplot(results3, aes(x = variable, y = common_name, fill = estimate))+
  geom_tile()+
  theme(axis.text.x = element_text(angle = 45, hjust=1, size = 18))+
  scale_fill_gradient2(low = "red",
                       mid = "white",
                       high = "blue",
                       midpoint = 0)+
  labs(x = NULL, y = NULL)

ggsave(
    filename = "tmpfigures/pre_abs_tileplot.png",
    plot = last_plot(),
    width = 18,
    height = 18,
    units = "cm",
    dpi = 200
  )

#counts the number of significant variables (ie how many species is each variable significant for?)
 results4 <- results3 %>% 
   select(variable, estimate) %>% 
   filter(!is.na(estimate)) %>% 
   group_by(variable) %>% 
   summarize(count = n()) %>% 
   arrange(desc(count))
 write.csv(results4, "tmpfigures/presabs_sigvariables.csv")

```






Model proportional abundances of each traits using a multinomial logistic regression 
1. temperature preferences - four categories
2. Fluvial dependence - 3 categories
2. spawning strategy - two categories
3. spawning season - nine categories

```{r}

library(foreign)
library(nnet)

counts <- fish_count_with_zeros %>%
  filter(gear == "efish_backpack",
         stock != "stock" | is.na(stock)) %>% #we never attributed ME data as stocked or natural, so well keep it all
  mutate(UID2 = UID) %>% 
  separate(UID, into = c("state", "remove"), sep=2) %>% 
  left_join(final_traits, by = "common_name") 

counts$state[counts$state == "de"] <- "NH"
counts$state[counts$state == "fg"] <- "NH"
counts <- counts %>% 
  left_join(temperature, by = c("state", "common_name")) %>% 
  left_join(origin, by = c("state", "common_name")) %>% 
  select(-remove) %>% 
  rename(UID = UID2)


#scale covariates
fishcovariates <- fishcovariates[complete.cases(fishcovariates),]
test <- fishcovariates[,c(2:3, 9:38)]
test <- data.frame(scale(test))
fishcovariates <- cbind((fishcovariates)[,c(1, 4:8)], test)






############### Temperature preference ######################
############### model built using all species ###############





#set up the temperature dataframe.  Want to count the number of cold, cool, warm, and eurythermal 
temp_counts <- counts %>% 
  filter(!is.na(tmp),
         tmp != "eury") %>% 
  group_by(UID) %>% 
  mutate(totalcount = sum(count)) %>% 
  ungroup()  %>% 
  group_by(UID, tmp) %>% 
  mutate(temp_count = sum(count)) %>%
  ungroup() %>% 
  select(UID, tmp, totalcount, temp_count) %>% 
  unique() %>% 
  mutate(propabun_tmp = temp_count/totalcount) %>% 
  filter(temp_count> 0)

#revalue counts of greater than 500 to be 500 -- eventually we want to edit the fish count file to exclude juveniles.. hopefully this will get rid of some of the really large counts..
temp_counts$temp_count[temp_counts$temp_count>500] <- 500

#plot the observed proportional abundance
shp <- left_join(fish_shp, temp_counts, by = "UID") %>%
  filter(!is.na(propabun_tmp)) 
ggplot(data = shp)+
  geom_sf(aes(fill = propabun_tmp, color = propabun_tmp), pch = 21, alpha = 0.7)+
  scale_fill_viridis_c(limits = c(0,1))+
  labs(fill = "Rel. Abun.")+
  guides(color = "none")+
  facet_wrap(~tmp, nrow = 1)+
    geom_sf(data = states, fill = NA, lwd = 0.3, color = "black")+
    theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
        strip.background = element_rect(fill = "grey70",
                                        colour = "black"),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/temp_propabun_baseline.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 300
  )

#for the multinomial analysis, we want the dependent variable to be catagores, rather than a proportion of different categories
#one way to do this, is to repeat each observation 'n' times
#for example, is a site had 5 cold spp and 5 cool spp, we would make five rows for cold and five rows for cool.
n <-  temp_counts$temp_count
temp_counts <- temp_counts[rep(seq_len(nrow(temp_counts)), n),]
temp_counts <- temp_counts %>% 
  select(tmp, UID) %>% 
  left_join(fishcovariates, by = "UID")

#convert the temperature designations to 'factor' variables. Reference level = 'warm' (all results interpreted in relation to "warm")
temp_counts$tmp2 <- relevel(as.factor(temp_counts$tmp), ref = "warm")

#put 20% of the data aside for testing
temp_counts <- temp_counts %>% 
  filter(!is.na(lat))
n_obs <- nrow(temp_counts)
permuted_rows <- sample(n_obs)
temp_counts <- temp_counts[permuted_rows,]
split <- round(n_obs * 0.8)
set.seed(32435)
train <- temp_counts[1:split, ]
test <- temp_counts[(split+1):n_obs, ]

#run the multinomial model
mdl <- multinom(tmp2 ~ 
                 annual_mean_summer_temp + 
                 BFI_HIST + 
                 LO7Q1DT_HIST +
                 W95_HIST + 
                 BFIWs +   
                 WtDepWs + 
                 PctOw_Ws +  
                 PctImp_Ws +  
                 pctAg_Ws + 
                 pctWetland_Cat + 
                 logMJJA_HIST + 
                 logRdCrsCat + 
                 logPctOw_Cat +
                 huc12_damden_sqkm +
                 huc8_damcount +
                 lat +
                 long +
                 ElevCat + 
                 logWsAreaSqKm,
                 data = train)
results <- summary(mdl)
saveRDS(mdl, "C:/Users/jenrogers/Documents/necascFreshwaterBio/model_objects/trait_temp_all_natural_spp.rds")

#validation prediction on testing data
test2 <- test %>% 
  select(-tmp, -tmp2) %>% 
  unique()
validation <- predict(mdl, newdata = test2, "probs")
validation <- cbind(validation, test2) 

test3 <- test %>% 
  select(tmp, UID) %>% 
  group_by(UID, tmp) %>% 
  summarise(count = n()) %>% 
  pivot_wider(names_from = tmp, values_from = count) %>% 
  mutate(totalcount = sum(cold, cool, warm, na.rm = T)) %>% 
  mutate(true_cold = cold/totalcount,
         true_cool = cool/totalcount,
         true_warm = warm/totalcount)
test3$true_cold[is.na(test3$true_cold)] <- 0
test3$true_cool[is.na(test3$true_cool)] <- 0
test3$true_warm[is.na(test3$true_warm)] <- 0

test3 <- left_join(validation, test3, by = "UID")
validation <- test3 %>% 
  select(true_cold, true_cool, true_warm, "warm.x", "cold.x", "cool.x") %>% 
  rename(predict_warm = "warm.x",
         predict_cool = "cool.x",
         predict_cold = "cold.x")

r2 <- cor(validation$predict_cold,  validation$true_cold)
ggplot(data = validation, aes(x = true_cold, y = predict_cold))+
  geom_jitter(alpha = 0.05, size = 3, width = 0.05, height = 0.05)+
  geom_smooth(method = "lm")+
  labs(x = "True Prop Cold", y = "Predicted Prop Cold")+
  annotate("text",x=.2,y=.2,label=r2,parse=TRUE, color = "red", size = 5)
ggsave(
    filename = "tmpfigures/Validation_fish_prop_cold.png",
    plot = last_plot(),    width = 14,    height = 9,    units = "cm",    dpi = 300
  )

r2 <- cor(validation$predict_cool,  validation$true_cool)
ggplot(data = validation, aes(x = true_cool, y = predict_cool))+
  geom_jitter(alpha = 0.05, size = 3, width = 0.05, height = 0.05)+
  geom_smooth(method = "lm")+
  labs(x = "True Prop Cool", y = "Predicted Prop Cool")+
  annotate("text",x=.2,y=.2,label=r2,parse=TRUE, color = "red", size = 5)
ggsave(
    filename = "tmpfigures/Validation_fish_prop_cool.png",
    plot = last_plot(),    width = 14,    height = 9,    units = "cm",    dpi = 300
  )

r2 <- cor(validation$predict_warm,  validation$true_warm)
ggplot(data = validation, aes(x = true_warm, y = predict_warm))+
  geom_jitter(alpha = 0.05, size = 3, width = 0.05, height = 0.05)+
  geom_smooth(method = "lm")+
  labs(x = "True Prop Warm", y = "Predicted Prop Warm")+
  annotate("text",x=.2,y=.2,label=r2,parse=TRUE, color = "red", size = 5)
ggsave(
    filename = "tmpfigures/Validation_fish_prop_warm.png",
    plot = last_plot(),    width = 14,    height = 9,    units = "cm",    dpi = 300
  )



#plot the OR and the 95% confidence interval for Cold fish (vs warm fish)
coef <- data.frame(results$coefficients) #make a coef table
coef <- coef %>%  # keep only the cold coefficients 
  mutate(temperature = rownames(coef)) %>% 
  filter(temperature == "cold") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:13, names_to = "variable", values_to = "coef")
se <- data.frame(results$standard.errors) #make a standard error table
se <- se %>%  #keep only the cold water standard errors
  mutate(temperature = rownames(se)) %>% 
  filter(temperature == "cold") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:13, names_to = "variable", values_to = "se")

#create a dataframe with the variables, coef and se in one dataframe
results2 <- data.frame( 
  "variable" = coef$variable,
  "coef" = coef$coef,
  "se" = se$se)

#calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results2 <- results2 %>% 
  mutate(z = coef/se,
         p = (1 - pnorm(abs(z), 0, 1)) * 2,
         CIlow = coef - (1.96*se),
         CIhigh = coef + (1.96*se),
         OR = exp(coef),
         ORCIlow = exp(CIlow),
         ORCIhigh = exp(CIhigh)) %>% 
  arrange(OR)
#the plot is ordering by the alphbatized letters of the variables, so we will make them factors ordered by the value of of the OR
results2$variable[results2$variable == "annual_mean_summer_temp"] <- "mean_summer_temp"
results2$variable <- factor(results2$variable, levels = results2$variable)

#dot plot of the OR and the CI. The CI are so tiny bc the sample size is super big
ggplot(data = arrange(results2, OR), aes(x = variable, y = OR))+
  geom_point()+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), width = 0)+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed")+
    theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          axis.title = element_text(size = 17),
          axis.text = element_text(size = 15))+
  labs(x = NULL,
       y = "Odds Ratio")

ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/coldtraitDotPlot.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )





#plot the OR and the 95% confidence interval for cool fish (vs warm fish)
coef <- data.frame(results$coefficients) #make a coef table
coef <- coef %>%  # keep only the cool coefficients 
  mutate(temperature = rownames(coef)) %>% 
  filter(temperature == "cool") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:13, names_to = "variable", values_to = "coef")
se <- data.frame(results$standard.errors) #make a standard error table
se <- se %>%  #keep only the cool water standard errors
  mutate(temperature = rownames(se)) %>% 
  filter(temperature == "cool") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:13, names_to = "variable", values_to = "se")

#create a dataframe with the variables, coef and se in one dataframe
results2 <- data.frame( 
  "variable" = coef$variable,
  "coef" = coef$coef,
  "se" = se$se)

#calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results2 <- results2 %>% 
  mutate(z = coef/se,
         p = (1 - pnorm(abs(z), 0, 1)) * 2,
         CIlow = coef - (1.96*se),
         CIhigh = coef + (1.96*se),
         OR = exp(coef),
         ORCIlow = exp(CIlow),
         ORCIhigh = exp(CIhigh)) %>% 
  arrange(OR)
#the plot is ordering by the alphbatized letters of the variables, so we will make them factors ordered by the value of of the OR
results2$variable[results2$variable == "annual_mean_summer_temp"] <- "mean_summer_temp"
results2$variable <- factor(results2$variable, levels = results2$variable)
#dot plot of the OR and the CI. The CI are so tiny bc the sample size is super big
ggplot(data = arrange(results2, OR), aes(x = variable, y = OR))+
  geom_point()+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), width = 0)+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed")+
    theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          axis.title = element_text(size = 17),
          axis.text = element_text(size = 15))+
  labs(x = NULL,
       y = "Odds Ratio")

ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/cooltraitDotPlot.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )


#odds = exp(logodds)
#probability = odds/(1+odds)












############### Temperature preference ######################
############### model built using only native species ###############



counts <- fish_count_with_zeros %>%
  filter(gear == "efish_backpack",
         stock != "stock" | is.na(stock)) %>% #we never attributed ME data as stocked or natural, so well keep it all
  mutate(UID2 = UID) %>% 
  separate(UID, into = c("state", "remove"), sep=2) %>% 
  left_join(final_traits, by = "common_name") 

counts$state[counts$state == "de"] <- "NH"
counts$state[counts$state == "fg"] <- "NH"
counts <- counts %>% 
  left_join(temperature, by = c("state", "common_name")) %>% 
  left_join(origin, by = c("state", "common_name")) %>% 
  select(-remove) %>% 
  rename(UID = UID2) %>% 
  filter(origin == "native")





#set up the temperature dataframe.  Want to count the number of cold, cool, warm, and eurythermal 
temp_counts <- counts %>% 
  filter(!is.na(tmp),
         tmp != "eury") %>% 
  group_by(UID) %>% 
  mutate(totalcount = sum(count)) %>% 
  ungroup()  %>% 
  group_by(UID, tmp) %>% 
  mutate(temp_count = sum(count)) %>%
  ungroup() %>% 
  select(UID, tmp, totalcount, temp_count) %>% 
  unique() %>% 
  mutate(propabun_tmp = temp_count/totalcount) %>% 
  filter(temp_count> 0)

#revalue counts of greater than 500 to be 500 -- eventually we want to edit the fish count file to exclude juveniles.. hopefully this will get rid of some of the really large counts..
temp_counts$temp_count[temp_counts$temp_count>500] <- 500

#plot the observed proportional abundance
shp <- left_join(fish_shp, temp_counts, by = "UID") %>%
  filter(!is.na(propabun_tmp)) 
ggplot(data = shp)+
  geom_sf(aes(fill = propabun_tmp, color = propabun_tmp), pch = 21, alpha = 0.7)+
  scale_fill_viridis_c(limits = c(0,1))+
  labs(fill = "Rel. Abun.")+
  guides(color = "none")+
  facet_wrap(~tmp, nrow = 1)+
    geom_sf(data = states, fill = NA, lwd = 0.3, color = "black")+
    theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
        strip.background = element_rect(fill = "grey70",
                                        colour = "black"),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/temp_propabun_baseline_native_only.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 300
  )

#for the multinomial analysis, we want the dependent variable to be catagores, rather than a proportion of different categories
#one way to do this, is to repeat each observation 'n' times
#for example, is a site had 5 cold spp and 5 cool spp, we would make five rows for cold and five rows for cool.
n <-  temp_counts$temp_count
temp_counts <- temp_counts[rep(seq_len(nrow(temp_counts)), n),]
temp_counts <- temp_counts %>% 
  select(tmp, UID) %>% 
  left_join(fishcovariates, by = "UID")

#convert the temperature designations to 'factor' variables. Reference level = 'cool' (all results interpreted in relation to "cool")
temp_counts$tmp2 <- relevel(as.factor(temp_counts$tmp), ref = "warm")

#run the multinomial model
mdl <- multinom(tmp2 ~ 
                 annual_mean_summer_temp + 
                 BFI_HIST + 
                 LO7Q1DT_HIST +
                 W95_HIST + 
                 BFIWs +   
                 WtDepWs + 
                 PctOw_Ws +  
                 PctImp_Ws +  
                 pctAg_Ws + 
                 pctWetland_Cat + 
                 logMJJA_HIST + 
                 logRdCrsCat + 
                 logPctOw_Cat,
                 data = temp_counts)
results <- summary(mdl)
saveRDS(mdl, "C:/Users/jenrogers/Documents/necascFreshwaterBio/model_objects/trait_temp_all_native_spp.rds")

#plot the OR and the 95% confidence interval for Cold fish (vs warm fish)
coef <- data.frame(results$coefficients) #make a coef table
coef <- coef %>%  # keep only the cold coefficients 
  mutate(temperature = rownames(coef)) %>% 
  filter(temperature == "cold") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:13, names_to = "variable", values_to = "coef")
se <- data.frame(results$standard.errors) #make a standard error table
se <- se %>%  #keep only the cold water standard errors
  mutate(temperature = rownames(se)) %>% 
  filter(temperature == "cold") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:13, names_to = "variable", values_to = "se")

#create a dataframe with the variables, coef and se in one dataframe
results2 <- data.frame( 
  "variable" = coef$variable,
  "coef" = coef$coef,
  "se" = se$se)

#calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results2 <- results2 %>% 
  mutate(z = coef/se,
         p = (1 - pnorm(abs(z), 0, 1)) * 2,
         CIlow = coef - (1.96*se),
         CIhigh = coef + (1.96*se),
         OR = exp(coef),
         ORCIlow = exp(CIlow),
         ORCIhigh = exp(CIhigh)) %>% 
  arrange(OR)
#the plot is ordering by the alphbatized letters of the variables, so we will make them factors ordered by the value of of the OR
results2$variable[results2$variable == "annual_mean_summer_temp"] <- "mean_summer_temp"
results2$variable <- factor(results2$variable, levels = results2$variable)

#dot plot of the OR and the CI. The CI are so tiny bc the sample size is super big
ggplot(data = arrange(results2, OR), aes(x = variable, y = OR))+
  geom_point()+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), width = 0)+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed")+
    theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          axis.title = element_text(size = 17),
          axis.text = element_text(size = 15))+
  labs(x = NULL,
       y = "Odds Ratio")

ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/coldtraitDotPlot_native_spp.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )





#plot the OR and the 95% confidence interval for cool fish (vs warm fish)
coef <- data.frame(results$coefficients) #make a coef table
coef <- coef %>%  # keep only the cool coefficients 
  mutate(temperature = rownames(coef)) %>% 
  filter(temperature == "cool") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:13, names_to = "variable", values_to = "coef")
se <- data.frame(results$standard.errors) #make a standard error table
se <- se %>%  #keep only the cool water standard errors
  mutate(temperature = rownames(se)) %>% 
  filter(temperature == "cool") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:13, names_to = "variable", values_to = "se")

#create a dataframe with the variables, coef and se in one dataframe
results2 <- data.frame( 
  "variable" = coef$variable,
  "coef" = coef$coef,
  "se" = se$se)

#calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results2 <- results2 %>% 
  mutate(z = coef/se,
         p = (1 - pnorm(abs(z), 0, 1)) * 2,
         CIlow = coef - (1.96*se),
         CIhigh = coef + (1.96*se),
         OR = exp(coef),
         ORCIlow = exp(CIlow),
         ORCIhigh = exp(CIhigh)) %>% 
  arrange(OR)
#the plot is ordering by the alphbatized letters of the variables, so we will make them factors ordered by the value of of the OR
results2$variable[results2$variable == "annual_mean_summer_temp"] <- "mean_summer_temp"
results2$variable <- factor(results2$variable, levels = results2$variable)
#dot plot of the OR and the CI. The CI are so tiny bc the sample size is super big
ggplot(data = arrange(results2, OR), aes(x = variable, y = OR))+
  geom_point()+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), width = 0)+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed")+
    theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          axis.title = element_text(size = 17),
          axis.text = element_text(size = 15))+
  labs(x = NULL,
       y = "Odds Ratio")

ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/cooltraitDotPlot_native_spp.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )


#odds = exp(logodds)
#probability = odds/(1+odds)












############### toleranace  ######################
############### model built using all species ###############





#set up the tolerance dataframe.  Want to count the number of fluvial specialist, dependent, and generalist spp
tol_counts <- counts %>% 
  filter(!is.na(tolerance)) %>% 
  group_by(UID) %>% 
  mutate(totalcount = sum(count)) %>% 
  ungroup()  %>% 
  group_by(UID, tolerance) %>% 
  mutate(tol_count = sum(count)) %>%
  ungroup() %>% 
  select(UID, tolerance, totalcount, tol_count) %>% 
  unique() %>% 
  mutate(propabun_tol = tol_count/totalcount) %>% 
  filter(tol_count> 0)

#revalue counts of greater than 500 to be 500 -- eventually we want to edit the fish count file to exclude juveniles.. hopefully this will get rid of some of the really large counts..
tol_counts$tol_count[tol_counts$tol_count>500] <- 500

#plot the observed proportional abundance
shp <- left_join(fish_shp, tol_counts, by = "UID") %>%
  filter(!is.na(propabun_tol)) 
ggplot(data = shp)+
  geom_sf(aes(fill = propabun_tol, color = propabun_tol), pch = 21, alpha = 0.7)+
  scale_fill_viridis_c(limits = c(0,1))+
  labs(fill = "Rel. Abun.")+
  guides(color = "none")+
  facet_wrap(~tolerance, nrow = 1)+
    geom_sf(data = states, fill = NA, lwd = 0.3, color = "black")+
    theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
        strip.background = element_rect(fill = "grey70",
                                        colour = "black"),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/tol_propabun_baseline.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 300
  )

#for the multinomial analysis, we want the dependent variable to be catagores, rather than a proportion of different categories
#one way to do this, is to repeat each observation 'n' times
#for example, is a site had 5 fluvial specialist spp and 5 generalist spp, we would make five rows for each.
n <-  tol_counts$tol_count
tol_counts <- tol_counts[rep(seq_len(nrow(tol_counts)), n),]
tol_counts <- tol_counts %>% 
  select(tolerance, UID) %>% 
  left_join(fishcovariates, by = "UID")

#convert the tolerance designations to 'factor' variables. Reference level = 'generalist' (all results interpreted in relation to "generalist")
tol_counts$tolerance2 <- relevel(as.factor(tol_counts$tolerance), ref = "generalist")

#put 20% of the data aside for testing
tol_counts <- tol_counts %>% 
  filter(!is.na(lat))
n_obs <- nrow(tol_counts)
permuted_rows <- sample(n_obs)
tol_counts <- tol_counts[permuted_rows,]
split <- round(n_obs * 0.8)
set.seed(32435)
train <- tol_counts[1:split, ]
test <- tol_counts[(split+1):n_obs, ]

#run the multinomial model
mdl <- multinom(tolerance2 ~ 
                 annual_mean_summer_temp + 
                 BFI_HIST + 
                 LO7Q1DT_HIST +
                 W95_HIST + 
                 BFIWs +   
                 WtDepWs + 
                 PctOw_Ws +  
                 PctImp_Ws +  
                 pctAg_Ws + 
                 pctWetland_Cat + 
                 logMJJA_HIST + 
                 logRdCrsCat + 
                 logPctOw_Cat +
                 huc12_damden_sqkm +
                 huc8_damcount +
                 lat +
                 long +
                 ElevCat + 
                 logWsAreaSqKm,
                 data = train)
results <- summary(mdl)
saveRDS(mdl, "C:/Users/jenrogers/Documents/necascFreshwaterBio/model_objects/trait_tol_all_natural_spp.rds")

#validation prediction on testing data
test2 <- test %>% 
  select(-tolerance, -tolerance2) %>% 
  unique()
validation <- predict(mdl, newdata = test2, "probs")
validation <- cbind(validation, test2) 

test3 <- test %>% 
  select(tolerance, UID) %>% 
  group_by(UID, tolerance) %>% 
  summarise(count = n()) %>% 
  pivot_wider(names_from = tolerance, values_from = count) %>% 
  mutate(totalcount = sum(generalist, `fluvial dependent`, `fluvial specialist`, na.rm = T)) %>% 
  mutate(true_gen = generalist/totalcount,
         true_dep = `fluvial dependent`/totalcount,
         true_spe = `fluvial specialist`/totalcount)
test3$true_gen[is.na(test3$true_gen)] <- 0
test3$true_dep[is.na(test3$true_dep)] <- 0
test3$true_spe[is.na(test3$true_spe)] <- 0

test3 <- left_join(validation, test3, by = "UID")
validation <- test3 %>% 
  select(true_gen, true_dep, true_spe, "generalist.x", "fluvial dependent.x", "fluvial specialist.x") %>% 
  rename(predict_gen = "generalist.x",
         predict_dep = "fluvial dependent.x",
         predict_spe = "fluvial specialist.x")

r2 <- cor(validation$predict_gen,  validation$true_gen)
ggplot(data = validation, aes(x = true_gen, y = predict_gen))+
  geom_jitter(alpha = 0.05, size = 3, width = 0.05, height = 0.05)+
  geom_smooth(method = "lm")+
  labs(x = "True Prop Generalist", y = "Predicted Prop Generalist")+
  annotate("text",x=.2,y=.2,label=r2,parse=TRUE, color = "red", size = 5)
ggsave(
    filename = "tmpfigures/Validation_fish_prop_Generalist.png",
    plot = last_plot(),    width = 14,    height = 9,    units = "cm",    dpi = 300
  )

r2 <- cor(validation$predict_dep,  validation$true_dep)
ggplot(data = validation, aes(x = true_dep, y = predict_dep))+
  geom_jitter(alpha = 0.05, size = 3, width = 0.05, height = 0.05)+
  geom_smooth(method = "lm")+
  labs(x = "True Prop fluvial dependent", y = "Predicted Prop fluvial dependent")+
  annotate("text",x=.2,y=.2,label=r2,parse=TRUE, color = "red", size = 5)
ggsave(
    filename = "tmpfigures/Validation_fish_prop_fluvdep.png",
    plot = last_plot(),    width = 14,    height = 9,    units = "cm",    dpi = 300
  )

r2 <- cor(validation$predict_spe,  validation$true_spe)
ggplot(data = validation, aes(x = true_spe, y = predict_spe))+
  geom_jitter(alpha = 0.05, size = 3, width = 0.05, height = 0.05)+
  geom_smooth(method = "lm")+
  labs(x = "True Prop fluvial specialist", y = "Predicted Prop fluvial specialist")+
  annotate("text",x=.2,y=.2,label=r2,parse=TRUE, color = "red", size = 5)
ggsave(
    filename = "tmpfigures/Validation_fish_prop_fluvspe.png",
    plot = last_plot(),    width = 14,    height = 9,    units = "cm",    dpi = 300
  )



#plot the OR and the 95% confidence interval for specialist fish (vs generalist fish)
coef <- data.frame(results$coefficients) #make a coef table
coef <- coef %>%  # keep only the specialist coefficients 
  mutate(tolerance = rownames(coef)) %>% 
  filter(tolerance == "fluvial specialist") %>% 
  select(-tolerance, -X.Intercept.) %>% 
  pivot_longer(1:13, names_to = "variable", values_to = "coef")
se <- data.frame(results$standard.errors) #make a standard error table
se <- se %>%  #keep only the fluvial specialist water standard errors
  mutate(tolerance = rownames(se)) %>% 
  filter(tolerance == "fluvial specialist") %>% 
  select(-tolerance, -X.Intercept.) %>% 
  pivot_longer(1:13, names_to = "variable", values_to = "se")

#create a dataframe with the variables, coef and se in one dataframe
results2 <- data.frame( 
  "variable" = coef$variable,
  "coef" = coef$coef,
  "se" = se$se)

#calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results2 <- results2 %>% 
  mutate(z = coef/se,
         p = (1 - pnorm(abs(z), 0, 1)) * 2,
         CIlow = coef - (1.96*se),
         CIhigh = coef + (1.96*se),
         OR = exp(coef),
         ORCIlow = exp(CIlow),
         ORCIhigh = exp(CIhigh)) %>% 
  arrange(OR)
#the plot is ordering by the alphbatized letters of the variables, so we will make them factors ordered by the value of of the OR
results2$variable[results2$variable == "annual_mean_summer_temp"] <- "mean_summer_temp"
results2$variable <- factor(results2$variable, levels = results2$variable)

#dot plot of the OR and the CI. The CI are so tiny bc the sample size is super big
ggplot(data = arrange(results2, OR), aes(x = variable, y = OR))+
  geom_point()+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), width = 0)+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed")+
    theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          axis.title = element_text(size = 17),
          axis.text = element_text(size = 15))+
  labs(x = NULL,
       y = "Odds Ratio")

ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/specialisttraitDotPlot.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )





#plot the OR and the 95% confidence interval for fluvial dependent fish (vs generalist fish)
coef <- data.frame(results$coefficients) #make a coef table
coef <- coef %>%  # keep only the fluvial dependent coefficients 
  mutate(tolerance = rownames(coef)) %>% 
  filter(tolerance == "fluvial dependent") %>% 
  select(-tolerance, -X.Intercept.) %>% 
  pivot_longer(1:13, names_to = "variable", values_to = "coef")
se <- data.frame(results$standard.errors) #make a standard error table
se <- se %>%  #keep only the fluvial dependent water standard errors
  mutate(tolerance = rownames(se)) %>% 
  filter(tolerance == "fluvial dependent") %>% 
  select(-tolerance, -X.Intercept.) %>% 
  pivot_longer(1:13, names_to = "variable", values_to = "se")

#create a dataframe with the variables, coef and se in one dataframe
results2 <- data.frame( 
  "variable" = coef$variable,
  "coef" = coef$coef,
  "se" = se$se)

#calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results2 <- results2 %>% 
  mutate(z = coef/se,
         p = (1 - pnorm(abs(z), 0, 1)) * 2,
         CIlow = coef - (1.96*se),
         CIhigh = coef + (1.96*se),
         OR = exp(coef),
         ORCIlow = exp(CIlow),
         ORCIhigh = exp(CIhigh)) %>% 
  arrange(OR)
#the plot is ordering by the alphbatized letters of the variables, so we will make them factors ordered by the value of of the OR
results2$variable[results2$variable == "annual_mean_summer_temp"] <- "mean_summer_temp"
results2$variable <- factor(results2$variable, levels = results2$variable)

#dot plot of the OR and the CI. The CI are so tiny bc the sample size is super big
ggplot(data = arrange(results2, OR), aes(x = variable, y = OR))+
  geom_point()+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), width = 0)+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed")+
    theme(panel.border = element_rect(colour = "black", fill = NA),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          axis.title = element_text(size = 17),
          axis.text = element_text(size = 15))+
  labs(x = NULL,
       y = "Odds Ratio")

ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/fluvdependenttraitDotPlot.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )


#odds = exp(logodds)
#probability = odds/(1+odds)


















############### Spawning timing ######################








#set up the timing dataframe (ie the season that spp spawn)
#combine 'f' and 'f/w' and combine sp with sp/su and su
counts$timing[counts$timing == "f"] <- "f/w"
counts$timing[counts$timing == "sp"] <- "sp/su"
counts$timing[counts$timing == "su"] <- "sp/su"
counts$timing[counts$timing == "sp/su/f"] <- "sp/su/f/w" #these are the extended spawners

counts <- counts %>% 
  filter(timing %in% c("f/w", "sp/su", "sp/su/f/w"))

sp_timing_counts <- counts%>% 
  group_by(UID) %>% 
  mutate(totalcount = sum(count)) %>% 
  ungroup() %>% 
  filter(!is.na(timing)) %>% 
  group_by(UID, timing) %>% 
  mutate(timing_count = sum(count)) %>%
  ungroup() %>% 
  select(UID, timing, totalcount, timing_count) %>% 
  unique() %>% 
  mutate(propabun_timing = timing_count/totalcount) %>% 
  select(-totalcount) %>% 
  filter(timing_count>0)

#revalue counts of greater than 500 to be 500 -- eventually we want to edit the fish count file to exclude juveniles.. hopefully this will get rid of some of the really large counts..
sp_timing_counts$timing_count[sp_timing_counts$timing_count>500] <- 500


#plot the observed proportional abundance
shp <- left_join(fish_shp, sp_timing_counts, by = "UID") %>%
  filter(!is.na(propabun_timing)) 
ggplot(data = shp)+
  geom_sf(aes(fill = propabun_timing, col = propabun_timing), alpha = 0.5, pch = 21)+
  facet_wrap(~timing, nrow = 2)




#for the multinomial analysis, we want the dependent variable to be catagores, rather than a proportion of different categories
#one way to do this, is to repeat each observation 'n' times
#for example, is a site had 5 cold spp and 5 cool spp, we would make five rows for cold and five rows for cool.
n <-  sp_timing_counts$timing_count
sp_timing_counts <- sp_timing_counts[rep(seq_len(nrow(sp_timing_counts)), n),]
sp_timing_counts <- sp_timing_counts %>% 
  select(timing, UID) %>% 
  left_join(fishcovariates, by = "UID")

#convert the temperature designations to 'factor' variables. Reference level = 'cool' (all results interpreted in relation to "cool")
sp_timing_counts$timing <- relevel(as.factor(sp_timing_counts$timing), ref = "sp/su/f/w")

#run the multinomial model
mdl <- multinom(timing ~ lat + 
                  long +
                  ElevCat +
                 annual_mean_summer_temp + 
                 BFI_HIST + 
                 LO7Q1DT_HIST +
                 W95_HIST + 
                 BFIWs +   
                 WtDepWs + 
                 PctOw_Ws +  
                 PctImp_Ws +  
                 pctAg_Ws + 
                 pctWetland_Cat + 
                 logMJJA_HIST + 
                 logRdCrsCat + 
                 logPctOw_Cat,
                 data = sp_timing_counts)
results <- summary(mdl)


#plot the OR and the 95% confidence interval for sp/su fish (vs sp/su/f/w fish)
coef <- data.frame(results$coefficients) #make a coef table
coef <- coef %>%  # keep only the sp/su coefficients 
  mutate(temperature = rownames(coef)) %>% 
  filter(temperature == "sp/su") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:16, names_to = "variable", values_to = "coef")
se <- data.frame(results$standard.errors) #make a standard error table
se <- se %>%  #keep only the sp/su water standard errors
  mutate(temperature = rownames(se)) %>% 
  filter(temperature == "sp/su") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:16, names_to = "variable", values_to = "se")

#create a dataframe with the variables, coef and se in one dataframe
results2 <- data.frame( 
  "variable" = coef$variable,
  "coef" = coef$coef,
  "se" = se$se)

#calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results2 <- results2 %>% 
  mutate(z = coef/se,
         p = (1 - pnorm(abs(z), 0, 1)) * 2,
         CIlow = coef - (1.96*se),
         CIhigh = coef + (1.96*se),
         OR = exp(coef),
         ORCIlow = exp(CIlow),
         ORCIhigh = exp(CIhigh)) %>% 
  arrange(OR)
#the plot is ordering by the alphbatized letters of the variables, so we will make them factors ordered by the value of of the OR
results2$variable <- factor(results2$variable, levels = results2$variable)
#dot plot of the OR and the CI. The CI are so tiny bc the sample size is super big
ggplot(data = arrange(results2, OR), aes(x = variable, y = OR))+
  geom_point()+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), width = 0)+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed")

ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/sp-sutraitDotPlot.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )





#plot the OR and the 95% confidence interval for f/w fish (vs sp/su/f/w fish)
coef <- data.frame(results$coefficients) #make a coef table
coef <- coef %>%  # keep only the f/w coefficients 
  mutate(temperature = rownames(coef)) %>% 
  filter(temperature == "f/w") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:16, names_to = "variable", values_to = "coef")
se <- data.frame(results$standard.errors) #make a standard error table
se <- se %>%  #keep only the f/w water standard errors
  mutate(temperature = rownames(se)) %>% 
  filter(temperature == "f/w") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:16, names_to = "variable", values_to = "se")

#create a dataframe with the variables, coef and se in one dataframe
results2 <- data.frame( 
  "variable" = coef$variable,
  "coef" = coef$coef,
  "se" = se$se)

#calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results2 <- results2 %>% 
  mutate(z = coef/se,
         p = (1 - pnorm(abs(z), 0, 1)) * 2,
         CIlow = coef - (1.96*se),
         CIhigh = coef + (1.96*se),
         OR = exp(coef),
         ORCIlow = exp(CIlow),
         ORCIhigh = exp(CIhigh)) %>% 
  arrange(OR)
#the plot is ordering by the alphbatized letters of the variables, so we will make them factors ordered by the value of of the OR
results2$variable <- factor(results2$variable, levels = results2$variable)
#dot plot of the OR and the CI. The CI are so tiny bc the sample size is super big
ggplot(data = arrange(results2, OR), aes(x = variable, y = OR))+
  geom_point()+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), width = 0)+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed")

ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/f-wtraitDotPlot.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )






############### Strategy ######################








unique(counts$strategy)

sp_strat_counts <- counts%>% 
  group_by(UID) %>% 
  mutate(totalcount = sum(count)) %>% 
  ungroup() %>% 
  filter(!is.na(strategy)) %>% 
  group_by(UID, strategy) %>% 
  mutate(strategy_count = sum(count)) %>%
  ungroup() %>% 
  select(UID, strategy, totalcount, strategy_count) %>% 
  unique() %>% 
  mutate(propabun_strat = strategy_count/totalcount) %>% 
  select(-totalcount)%>% 
  filter(strategy_count>0)



#revalue counts of greater than 500 to be 500 -- eventually we want to edit the fish count file to exclude juveniles.. hopefully this will get rid of some of the really large counts..
sp_strat_counts$strategy_count[sp_strat_counts$strategy_count>1000] <- 1000

#plot the observed proportional abundance
shp <- left_join(fish_shp, sp_strat_counts, by = "UID") %>%
  filter(!is.na(propabun_strat)) 
ggplot(data = shp)+
  geom_sf(aes(fill = propabun_strat, col = propabun_strat), alpha = 0.5, pch = 21)+
  facet_wrap(~strategy, nrow = 1)



#for the multinomial analysis, we want the dependent variable to be catagores, rather than a proportion of different categories
#one way to do this, is to repeat each observation 'n' times
#for example, is a site had 5 cold spp and 5 cool spp, we would make five rows for cold and five rows for cool.
n <-  sp_strat_counts$strategy_count
sp_strat_counts <- sp_strat_counts[rep(seq_len(nrow(sp_strat_counts)), n),]
sp_strat_counts <- sp_strat_counts %>% 
  select(strategy, UID) %>% 
  left_join(fishcovariates, by = "UID")

#convert the temperature designations to 'factor' variables. Reference level = 'cool' (all results interpreted in relation to "cool")
sp_strat_counts$strategy <- relevel(as.factor(sp_strat_counts$strategy), ref = "extended")

#run the multinomial model
mdl <- multinom(strategy ~ lat + 
                  long +
                  ElevCat +
                 annual_mean_summer_temp + 
                 BFI_HIST + 
                 LO7Q1DT_HIST +
                 W95_HIST + 
                 BFIWs +   
                 WtDepWs + 
                 PctOw_Ws +  
                 PctImp_Ws +  
                 pctAg_Ws + 
                 pctWetland_Cat + 
                 logMJJA_HIST + 
                 logRdCrsCat + 
                 logPctOw_Cat,
                 data = sp_strat_counts)
results <- summary(mdl)


#plot the OR and the 95% confidence interval for narrow fish (vs extended fish)
coef <- data.frame(results$coefficients) #make a coef table
coef <- coef %>%  # keep only the narrow coefficients 
  mutate(variable = rownames(coef)) %>% 
  rename(coef = results.coefficients)
se <- data.frame(results$standard.errors) #make a standard error table
se <- se %>%  #keep only the narrow water standard errors
  mutate(variable = rownames(se))  %>% 
  rename(se = results.standard.errors)

#create a dataframe with the variables, coef and se in one dataframe
results2 <- data.frame( 
  "variable" = coef$variable,
  "coef" = coef$coef,
  "se" = se$se)

#calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results2 <- results2 %>% 
  mutate(z = coef/se,
         p = (1 - pnorm(abs(z), 0, 1)) * 2,
         CIlow = coef - (1.96*se),
         CIhigh = coef + (1.96*se),
         OR = exp(coef),
         ORCIlow = exp(CIlow),
         ORCIhigh = exp(CIhigh)) %>% 
  arrange(OR)
#the plot is ordering by the alphbatized letters of the variables, so we will make them factors ordered by the value of of the OR
results2$variable <- factor(results2$variable, levels = results2$variable)
#dot plot of the OR and the CI. The CI are so tiny bc the sample size is super big
ggplot(data = arrange(results2, OR), aes(x = variable, y = OR))+
  geom_point()+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), width = 0)+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed")

ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/narrowtraitDotPlot.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )





############### VELOCITY ######################







table(counts$velocity)

counts$velocity[counts$velocity == "fast-mod"] <- "mod"
counts$velocity[counts$velocity == "slow-mod"] <- "mod"

vel_counts <- counts%>% 
  filter(!velocity == "any") %>% 
  group_by(UID) %>% 
  mutate(totalcount = sum(count)) %>% 
  ungroup() %>% 
  filter(!is.na(velocity)) %>% 
  group_by(UID, velocity) %>% 
  mutate(velocity_count = sum(count)) %>%
  ungroup() %>% 
  select(UID, velocity, totalcount, velocity_count) %>% 
  unique() %>% 
  mutate(propabun_vel = velocity_count/totalcount) %>% 
  select(-totalcount)

#plot the observed proportional abundance
shp <- left_join(fish_shp, vel_counts, by = "UID") %>%
  filter(!is.na(propabun_vel)) 
ggplot(data = shp)+
  geom_sf(aes(fill = propabun_vel, col = propabun_vel), pch = 21)+
  facet_wrap(~velocity, nrow = 2)




#for the multinomial analysis, we want the dependent variable to be catagores, rather than a proportion of different categories
#one way to do this, is to repeat each observation 'n' times
#for example, is a site had 5 cold spp and 5 cool spp, we would make five rows for cold and five rows for cool.
n <-  vel_counts$velocity_count
vel_counts <- vel_counts[rep(seq_len(nrow(vel_counts)), n),]
vel_counts <- vel_counts %>% 
  select(velocity, UID) %>% 
  left_join(fishcovariates, by = "UID")

#convert the temperature designations to 'factor' variables. Reference level = 'cool' (all results interpreted in relation to "cool")
vel_counts$velocity <- relevel(as.factor(vel_counts$velocity), ref = "slow")

#run the multinomial model
mdl <- multinom(velocity ~ lat + 
                  long +
                  ElevCat +
                 annual_mean_summer_temp + 
                 BFI_HIST + 
                 LO7Q1DT_HIST +
                 W95_HIST + 
                 BFIWs +   
                 WtDepWs + 
                 PctOw_Ws +  
                 PctImp_Ws +  
                 pctAg_Ws + 
                 pctWetland_Cat + 
                 logMJJA_HIST + 
                 logRdCrsCat + 
                 logPctOw_Cat,
                 data = vel_counts)
results <- summary(mdl)


#plot the OR and the 95% confidence interval for mod fish (vs slow fish)
coef <- data.frame(results$coefficients) #make a coef table
coef <- coef %>%  # keep only the mod coefficients 
  mutate(temperature = rownames(coef)) %>% 
  filter(temperature == "mod") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:16, names_to = "variable", values_to = "coef")
se <- data.frame(results$standard.errors) #make a standard error table
se <- se %>%  #keep only the mod water standard errors
  mutate(temperature = rownames(se)) %>% 
  filter(temperature == "mod") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:16, names_to = "variable", values_to = "se")

#create a dataframe with the variables, coef and se in one dataframe
results2 <- data.frame( 
  "variable" = coef$variable,
  "coef" = coef$coef,
  "se" = se$se)

#calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results2 <- results2 %>% 
  mutate(z = coef/se,
         p = (1 - pnorm(abs(z), 0, 1)) * 2,
         CIlow = coef - (1.96*se),
         CIhigh = coef + (1.96*se),
         OR = exp(coef),
         ORCIlow = exp(CIlow),
         ORCIhigh = exp(CIhigh)) %>% 
  arrange(OR)
#the plot is ordering by the alphbatized letters of the variables, so we will make them factors ordered by the value of of the OR
results2$variable <- factor(results2$variable, levels = results2$variable)
#dot plot of the OR and the CI. The CI are so tiny bc the sample size is super big
ggplot(data = arrange(results2, OR), aes(x = variable, y = OR))+
  geom_point()+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), width = 0)+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed")

ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/modtraitDotPlot.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )





#plot the OR and the 95% confidence interval for fast fish (vs slow fish)
coef <- data.frame(results$coefficients) #make a coef table
coef <- coef %>%  # keep only the fast coefficients 
  mutate(temperature = rownames(coef)) %>% 
  filter(temperature == "fast") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:16, names_to = "variable", values_to = "coef")
se <- data.frame(results$standard.errors) #make a standard error table
se <- se %>%  #keep only the fast water standard errors
  mutate(temperature = rownames(se)) %>% 
  filter(temperature == "fast") %>% 
  select(-temperature, -X.Intercept.) %>% 
  pivot_longer(1:16, names_to = "variable", values_to = "se")

#create a dataframe with the variables, coef and se in one dataframe
results2 <- data.frame( 
  "variable" = coef$variable,
  "coef" = coef$coef,
  "se" = se$se)

#calucate the z score, pvalue, and the upr and lwr CI, and then exponentiate the coef and upr/lower bounds to get odds ratio units
results2 <- results2 %>% 
  mutate(z = coef/se,
         p = (1 - pnorm(abs(z), 0, 1)) * 2,
         CIlow = coef - (1.96*se),
         CIhigh = coef + (1.96*se),
         OR = exp(coef),
         ORCIlow = exp(CIlow),
         ORCIhigh = exp(CIhigh)) %>% 
  arrange(OR)
#the plot is ordering by the alphbatized letters of the variables, so we will make them factors ordered by the value of of the OR
results2$variable <- factor(results2$variable, levels = results2$variable)
#dot plot of the OR and the CI. The CI are so tiny bc the sample size is super big
ggplot(data = arrange(results2, OR), aes(x = variable, y = OR))+
  geom_point()+
  geom_errorbar(aes(ymin = ORCIlow, ymax = ORCIhigh), width = 0)+
  coord_flip()+
  geom_hline(yintercept = 1, color  = "red", linetype = "dashed")

ggsave(
    filename = "C:/Users/jenrogers/Documents/git/FreshwaterBio/FreshwaterBio/tmpfigures/fasttraitDotPlot.png",
    plot = last_plot(),
    width = 14,
    height = 9,
    units = "cm",
    dpi = 200
  )









```


